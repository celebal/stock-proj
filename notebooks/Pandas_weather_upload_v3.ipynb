{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Weather DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate station data by distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "cities = [\"ATL_stations\",\"CH_stations\",\"LA_stations\",\"NYC_stations\",\"SD_stations\",\"SF_stations\"]\n",
    "#Aggregate Station Location tuples \n",
    "stations_data = pd.DataFrame()\n",
    "for city in cities:\n",
    "    path = 'station_locations/%s.txt' % city\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True,header=None,error_bad_lines=False)\n",
    "        frame['city'] = city\n",
    "        stations_data = stations_data.append(frame,ignore_index=True)\n",
    "stations_data = stations_data.rename(columns={0:\"distance\",1:\"station_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ATLshortlist = stations_data[(stations_data.city == \"ATL_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "CHshortlist = stations_data[(stations_data.city == \"CH_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "LAshortlist = stations_data[(stations_data.city == \"LA_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "NYCshortlist = stations_data[(stations_data.city == \"NYC_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "SDshortlist = stations_data[(stations_data.city == \"SD_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "SFshortlist = stations_data[(stations_data.city == \"SF_stations\") & (stations_data.distance <= 100)][['station_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and Load Data \n",
    "###### Merge datasets from each station with PARAM_STATION-NAME as default column header\n",
    "##### Process results in 10 stations per city\n",
    "##### UPDATE: Frame.query removes scrappy data (missing data will still exist for some!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######ATL Weather######\n",
    "ATL_stations = [];\n",
    "ATL_weather = pd.DataFrame()\n",
    "for station in ATLshortlist['station_name']:\n",
    "    path = 'ATL/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        if frame.shape[0] >= 12650:\n",
    "            ATL_stations.append(station);\n",
    "            if ATL_weather.empty:\n",
    "                ATL_weather = ATL_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                ATL_weather = ATL_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "ATL_weather = ATL_weather.groupby('DATE').mean()\n",
    "ATL_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######CH Weather######\n",
    "CH_stations = [];\n",
    "CH_weather = pd.DataFrame()\n",
    "for station in CHshortlist['station_name']:\n",
    "    path = 'CH/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        if frame.shape[0] >= 12764:\n",
    "            CH_stations.append(station)\n",
    "            if CH_weather.empty:\n",
    "                CH_weather = CH_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                CH_weather = CH_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "CH_weather = CH_weather.groupby('DATE').mean()\n",
    "CH_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######NYC Weather######\n",
    "NYC_stations = [];\n",
    "NYC_weather = pd.DataFrame()\n",
    "for station in NYCshortlist['station_name']:\n",
    "    path = 'NYC/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        if frame.shape[0] >= 12700:\n",
    "            NYC_stations.append(station)\n",
    "            if NYC_weather.empty:\n",
    "                NYC_weather = NYC_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                NYC_weather = NYC_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "NYC_weather = NYC_weather.groupby('DATE').mean()\n",
    "NYC_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######LA Weather######\n",
    "LA_stations = [];\n",
    "LA_weather = pd.DataFrame()\n",
    "for station in LAshortlist['station_name']:\n",
    "    path = 'LA/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        if frame.shape[0] >= 12600: \n",
    "            LA_stations.append(station)\n",
    "            if LA_weather.empty:\n",
    "                LA_weather = LA_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                LA_weather = LA_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "LA_weather = LA_weather.groupby('DATE').mean()\n",
    "LA_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######SF Weather######\n",
    "SF_stations = [];\n",
    "SF_weather = pd.DataFrame()\n",
    "for station in SFshortlist['station_name']:\n",
    "    path = 'SF/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        if frame.shape[0] >= 12784: \n",
    "            SF_stations.append(station)\n",
    "            if SF_weather.empty:\n",
    "                SF_weather = SF_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                SF_weather = SF_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "SF_weather = SF_weather.groupby('DATE').mean()\n",
    "SF_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######SD Weather######\n",
    "SD_stations = [];\n",
    "SD_weather = pd.DataFrame()\n",
    "for station in SDshortlist['station_name']:\n",
    "    path = 'SD/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        if frame.shape[0] >= 12600: \n",
    "            SD_stations.append(station)\n",
    "            if SD_weather.empty:\n",
    "                SD_weather = SD_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                SD_weather = SD_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "SD_weather = SD_weather.groupby('DATE').mean()\n",
    "SD_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Logger\n",
    "##### True indicates a missing data row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City stations missing data\n",
      "Station USC00300889\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USC00305426\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014732\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094728\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094745\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094789\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USC00283951\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USC00286055\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014734\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Station USW00093730\n",
      "False    12628\n",
      "dtype: int64\n",
      "\n",
      "Atlanta stations missing data\n",
      "Station USC00092283\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USC00092485\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USC00093060\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USC00093621\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USW00003813\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USW00013873\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USW00013874\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USW00093842\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USC00018469\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "Station USW00013871\n",
      "False    12593\n",
      "dtype: int64\n",
      "\n",
      "San Francisco stations missing data\n",
      "Station USC00043578\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USC00045795\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USC00047916\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USC00049742\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023232\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023233\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023234\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023237\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023271\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023272\n",
      "False    12737\n",
      "dtype: int64\n",
      "\n",
      "San Diego stations missing data\n",
      "Station USC00040983\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USC00042239\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USC00042713\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USC00043914\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USC00044223\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USC00047888\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USW00003104\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USW00003164\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023129\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023188\n",
      "False    11746\n",
      "dtype: int64\n",
      "\n",
      "Los Angeles stations missing data\n",
      "Station USC00041194\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USC00046624\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USC00046719\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USC00047888\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USC00049152\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USC00049785\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USW00003159\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023129\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023174\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Station USW00093134\n",
      "False    11962\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USC00472869\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USC00473058\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USC00473453\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USC00476200\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014839\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USC00125174\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014848\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USC00113262\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094822\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094846\n",
      "False    12652\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"New York City stations missing data\")\n",
    "for station in NYC_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(NYC_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Atlanta stations missing data\")\n",
    "for station in ATL_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(ATL_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "    \n",
    "print(\"San Francisco stations missing data\")\n",
    "for station in SF_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(SF_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"San Diego stations missing data\")\n",
    "for station in SD_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(SD_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Los Angeles stations missing data\")\n",
    "for station in LA_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(LA_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Chicago stations missing data\")\n",
    "for station in CH_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(CH_weather)['TMIN_'+station].value_counts())\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge Datasets from each stock with PARAM_STOCK-NAME as default columns           \n",
    "######Stock Data######\n",
    "stocks = ['Apple, Inc Stock','International Business Machines Stock','Wal-Mart Stores, Inc Common St Stock','FedEx Corporation','The Boeing Company']\n",
    "stock_data = pd.DataFrame()\n",
    "for stock in stocks:\n",
    "    path = 'Stock Data/%s.csv' % stock\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path)\n",
    "        frame.columns = ['DATE','OPEN_'+stock,'HIGH_'+stock,'LOW_'+stock,'CLOSE_'+stock,'VOLUME_'+stock,'ADJ CLOSE_'+stock]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        for column in frame.columns:\n",
    "            if column != 'DATE':\n",
    "                frame['PRE'+column] = frame[column].shift(-1)\n",
    "        if stock_data.empty:\n",
    "            stock_data = stock_data.append(frame,ignore_index=True)\n",
    "        else:\n",
    "            stock_data = stock_data.merge(frame, on='DATE', how='inner')\n",
    "stock_data = stock_data.groupby('DATE').mean()\n",
    "stock_data.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge Datasets from each stock with CITY-NAME_sunlight as default columns\n",
    "#####Sunlight Data######\n",
    "cities = ['ATL_sunlight','NYC_sunlight','LA_sunlight','SF_sunlight','SD_sunlight','CH_sunlight']\n",
    "sunlight_data = pd.DataFrame()\n",
    "for city in cities:\n",
    "    path = 'Sunlight_data/%s.csv' % city\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True,keep_date_col=True, header=None)\n",
    "        frame = frame.iloc[:,0:2]\n",
    "        frame.columns = ['DATE',city]\n",
    "        frame['DATE'] = pd.to_datetime(frame['DATE'])\n",
    "        if sunlight_data.empty:\n",
    "            sunlight_data = sunlight_data.append(frame,ignore_index=True)\n",
    "        else:\n",
    "            sunlight_data = sunlight_data.merge(frame, on='DATE', how='inner')\n",
    "sunlight_data = sunlight_data.groupby('DATE').mean()\n",
    "sunlight_data.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TMAX_USC00092283</th>\n",
       "      <th>TMIN_USC00092283</th>\n",
       "      <th>SNOW_USC00092283</th>\n",
       "      <th>SNWD_USC00092283</th>\n",
       "      <th>PRCP_USC00092283</th>\n",
       "      <th>TMAX_USC00092485</th>\n",
       "      <th>TMIN_USC00092485</th>\n",
       "      <th>SNOW_USC00092485</th>\n",
       "      <th>SNWD_USC00092485</th>\n",
       "      <th>...</th>\n",
       "      <th>LOW_The Boeing Company</th>\n",
       "      <th>CLOSE_The Boeing Company</th>\n",
       "      <th>VOLUME_The Boeing Company</th>\n",
       "      <th>ADJ CLOSE_The Boeing Company</th>\n",
       "      <th>PREOPEN_The Boeing Company</th>\n",
       "      <th>PREHIGH_The Boeing Company</th>\n",
       "      <th>PRELOW_The Boeing Company</th>\n",
       "      <th>PRECLOSE_The Boeing Company</th>\n",
       "      <th>PREVOLUME_The Boeing Company</th>\n",
       "      <th>PREADJ CLOSE_The Boeing Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>156</td>\n",
       "      <td>-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>-33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.625028</td>\n",
       "      <td>36.999991</td>\n",
       "      <td>816600</td>\n",
       "      <td>2.457737</td>\n",
       "      <td>36.999991</td>\n",
       "      <td>36.999991</td>\n",
       "      <td>36.124988</td>\n",
       "      <td>36.874978</td>\n",
       "      <td>1828200</td>\n",
       "      <td>2.449433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>111</td>\n",
       "      <td>-39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>-50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>37.250009</td>\n",
       "      <td>1157400</td>\n",
       "      <td>2.474345</td>\n",
       "      <td>36.874978</td>\n",
       "      <td>37.250009</td>\n",
       "      <td>36.625028</td>\n",
       "      <td>36.999991</td>\n",
       "      <td>816600</td>\n",
       "      <td>2.457737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>89</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>139</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.749969</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>1181000</td>\n",
       "      <td>2.466041</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>37.624972</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>37.250009</td>\n",
       "      <td>1157400</td>\n",
       "      <td>2.474345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>83</td>\n",
       "      <td>-33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>38.375034</td>\n",
       "      <td>1158200</td>\n",
       "      <td>2.549075</td>\n",
       "      <td>37.250009</td>\n",
       "      <td>37.375022</td>\n",
       "      <td>36.749969</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>1181000</td>\n",
       "      <td>2.466041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>150</td>\n",
       "      <td>-33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.125012</td>\n",
       "      <td>38.499975</td>\n",
       "      <td>1458200</td>\n",
       "      <td>2.557374</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>38.375034</td>\n",
       "      <td>37.125000</td>\n",
       "      <td>38.375034</td>\n",
       "      <td>1158200</td>\n",
       "      <td>2.549075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>2011-11-23</td>\n",
       "      <td>217</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>244</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.330002</td>\n",
       "      <td>62.360001</td>\n",
       "      <td>4273000</td>\n",
       "      <td>57.248141</td>\n",
       "      <td>65.300003</td>\n",
       "      <td>65.440002</td>\n",
       "      <td>63.880001</td>\n",
       "      <td>64.349998</td>\n",
       "      <td>5000300</td>\n",
       "      <td>59.075012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>2011-11-25</td>\n",
       "      <td>172</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.119999</td>\n",
       "      <td>62.779999</td>\n",
       "      <td>2122300</td>\n",
       "      <td>57.633710</td>\n",
       "      <td>63.619999</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>62.330002</td>\n",
       "      <td>62.360001</td>\n",
       "      <td>4273000</td>\n",
       "      <td>57.248141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>94</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.510002</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>12018200</td>\n",
       "      <td>65.161533</td>\n",
       "      <td>67.080002</td>\n",
       "      <td>68.750000</td>\n",
       "      <td>66.989998</td>\n",
       "      <td>68.690002</td>\n",
       "      <td>8601100</td>\n",
       "      <td>63.059251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>2011-12-14</td>\n",
       "      <td>172</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.720001</td>\n",
       "      <td>69.940002</td>\n",
       "      <td>5999900</td>\n",
       "      <td>64.206784</td>\n",
       "      <td>71.669998</td>\n",
       "      <td>72.650002</td>\n",
       "      <td>70.620003</td>\n",
       "      <td>70.900002</td>\n",
       "      <td>7555600</td>\n",
       "      <td>65.088089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6592</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>161</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.480003</td>\n",
       "      <td>74.290001</td>\n",
       "      <td>5849400</td>\n",
       "      <td>68.200199</td>\n",
       "      <td>72.730003</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>72.059998</td>\n",
       "      <td>73.589996</td>\n",
       "      <td>5471700</td>\n",
       "      <td>67.557576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6593 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE  TMAX_USC00092283  TMIN_USC00092283  SNOW_USC00092283  \\\n",
       "0    1980-12-12               156               -28                 0   \n",
       "1    1980-12-15               111               -39                 0   \n",
       "2    1980-12-16                89                17                 0   \n",
       "3    1980-12-17                83               -33                 0   \n",
       "4    1980-12-18               150               -33                 0   \n",
       "...         ...               ...               ...               ...   \n",
       "6588 2011-11-23               217               128                 0   \n",
       "6589 2011-11-25               172                11                 0   \n",
       "6590 2011-12-01                94               -22                 0   \n",
       "6591 2011-12-14               172                56                 0   \n",
       "6592 2011-12-22               161               111                 0   \n",
       "\n",
       "      SNWD_USC00092283  PRCP_USC00092283  TMAX_USC00092485  TMIN_USC00092485  \\\n",
       "0                    0                 0                94               -33   \n",
       "1                    0                 0               128               -50   \n",
       "2                    0                 8               139               -17   \n",
       "3                    0                 0               106               -22   \n",
       "4                    0                 0               100               -50   \n",
       "...                ...               ...               ...               ...   \n",
       "6588                 0               117               244               122   \n",
       "6589                 0                 0               194                -6   \n",
       "6590                 0                 0                78               -39   \n",
       "6591                 0                 0               200                39   \n",
       "6592                 0                20               200               128   \n",
       "\n",
       "      SNOW_USC00092485  SNWD_USC00092485               ...                 \\\n",
       "0                    0                 0               ...                  \n",
       "1                    0                 0               ...                  \n",
       "2                    0                 0               ...                  \n",
       "3                    0                 0               ...                  \n",
       "4                    0                 0               ...                  \n",
       "...                ...               ...               ...                  \n",
       "6588                 0                 0               ...                  \n",
       "6589                 0                 0               ...                  \n",
       "6590                 0                 0               ...                  \n",
       "6591                 0                 0               ...                  \n",
       "6592                 0                 0               ...                  \n",
       "\n",
       "      LOW_The Boeing Company  CLOSE_The Boeing Company  \\\n",
       "0                  36.625028                 36.999991   \n",
       "1                  37.125000                 37.250009   \n",
       "2                  36.749969                 37.125000   \n",
       "3                  37.125000                 38.375034   \n",
       "4                  38.125012                 38.499975   \n",
       "...                      ...                       ...   \n",
       "6588               62.330002                 62.360001   \n",
       "6589               62.119999                 62.779999   \n",
       "6590               68.510002                 70.980003   \n",
       "6591               69.720001                 69.940002   \n",
       "6592               73.480003                 74.290001   \n",
       "\n",
       "      VOLUME_The Boeing Company  ADJ CLOSE_The Boeing Company  \\\n",
       "0                        816600                      2.457737   \n",
       "1                       1157400                      2.474345   \n",
       "2                       1181000                      2.466041   \n",
       "3                       1158200                      2.549075   \n",
       "4                       1458200                      2.557374   \n",
       "...                         ...                           ...   \n",
       "6588                    4273000                     57.248141   \n",
       "6589                    2122300                     57.633710   \n",
       "6590                   12018200                     65.161533   \n",
       "6591                    5999900                     64.206784   \n",
       "6592                    5849400                     68.200199   \n",
       "\n",
       "      PREOPEN_The Boeing Company  PREHIGH_The Boeing Company  \\\n",
       "0                      36.999991                   36.999991   \n",
       "1                      36.874978                   37.250009   \n",
       "2                      37.125000                   37.624972   \n",
       "3                      37.250009                   37.375022   \n",
       "4                      37.125000                   38.375034   \n",
       "...                          ...                         ...   \n",
       "6588                   65.300003                   65.440002   \n",
       "6589                   63.619999                   63.750000   \n",
       "6590                   67.080002                   68.750000   \n",
       "6591                   71.669998                   72.650002   \n",
       "6592                   72.730003                   73.709999   \n",
       "\n",
       "      PRELOW_The Boeing Company  PRECLOSE_The Boeing Company  \\\n",
       "0                     36.124988                    36.874978   \n",
       "1                     36.625028                    36.999991   \n",
       "2                     37.125000                    37.250009   \n",
       "3                     36.749969                    37.125000   \n",
       "4                     37.125000                    38.375034   \n",
       "...                         ...                          ...   \n",
       "6588                  63.880001                    64.349998   \n",
       "6589                  62.330002                    62.360001   \n",
       "6590                  66.989998                    68.690002   \n",
       "6591                  70.620003                    70.900002   \n",
       "6592                  72.059998                    73.589996   \n",
       "\n",
       "      PREVOLUME_The Boeing Company  PREADJ CLOSE_The Boeing Company  \n",
       "0                          1828200                         2.449433  \n",
       "1                           816600                         2.457737  \n",
       "2                          1157400                         2.474345  \n",
       "3                          1181000                         2.466041  \n",
       "4                          1158200                         2.549075  \n",
       "...                            ...                              ...  \n",
       "6588                       5000300                        59.075012  \n",
       "6589                       4273000                        57.248141  \n",
       "6590                       8601100                        63.059251  \n",
       "6591                       7555600                        65.088089  \n",
       "6592                       5471700                        67.557576  \n",
       "\n",
       "[6593 rows x 367 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "data_frames = [ATL_weather,CH_weather,NYC_weather,LA_weather,SD_weather,SF_weather,sunlight_data,stock_data]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,how='inner',suffixes=('','_y'), on='DATE'), data_frames)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TMAX_AVG = [0 for x in range(len(df_final.index))]\n",
    "zipped = zip(list(df_final.columns.values),TMAX_AVG)\n",
    "count=0\n",
    "for i in list(df_final.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_AVG=TMAX_AVG+df_final.ix[:,i]\n",
    "\n",
    "\n",
    "################################################333\n",
    "TMAX_ATL = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_ATL=TMAX_ATL+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_ATL= TMAX_ATL/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMAX_CH = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_CH=TMAX_CH+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_CH= TMAX_CH/count \n",
    "###################################################3\n",
    "################################################333\n",
    "\n",
    "TMAX_LA = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_LA=TMAX_LA+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_LA= TMAX_LA/count\n",
    "\n",
    "###################################################3\n",
    "################################################333\n",
    "TMAX_NYC = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_NYC=TMAX_NYC+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_NYC= TMAX_NYC/count \n",
    "###################################################3\n",
    "################################################333\n",
    "\n",
    "TMAX_SD = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_SD=TMAX_SD+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_SD= TMAX_SD/count\n",
    "###################################################3\n",
    "################################################333\n",
    "TMAX_SF = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_SF=TMAX_SF+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_SF= TMAX_SF/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_ATL = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_ATL=TMIN_ATL+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_ATL= TMIN_ATL/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_CH = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_CH=TMIN_CH+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_CH= TMIN_CH/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_LA = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_LA=TMIN_LA+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_LA= TMIN_LA/count\n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_NYC = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_NYC=TMIN_NYC+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_NYC= TMIN_NYC/count \n",
    "###################################################3\n",
    "################################################333\n",
    "\n",
    "TMIN_SD = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_SD=TMIN_SD+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_SD= TMIN_SD/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_SF = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_SF=TMIN_SF+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_SF= TMIN_SF/count \n",
    "###################################################3\n",
    "##################################################\n",
    "\n",
    "SNOW_ATL = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_ATL=SNOW_ATL+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_ATL= SNOW_ATL/count \n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNOW_NYC = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_NYC=SNOW_NYC+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_NYC= SNOW_NYC/count \n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_CH = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_CH=SNOW_CH+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_CH= SNOW_CH/count\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_LA = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_LA=SNOW_LA+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_LA= SNOW_LA/count\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_SD = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_SD=SNOW_SD+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_SD= SNOW_SD/count\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_SF = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_SF=SNOW_SF+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_SF= SNOW_SF/count \n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNWD_ATL = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_ATL=SNWD_ATL+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_ATL= SNWD_ATL/count \n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_NYC = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_NYC=SNWD_NYC+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_NYC= SNWD_NYC/count\n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_CH = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_CH=SNWD_CH+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_CH= SNWD_CH/count \n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_LA = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_LA=SNWD_LA+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_LA= SNWD_LA/count \n",
    "\n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_SD = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_SD=SNWD_SD+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_SD= SNWD_SD/count \n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "SNWD_SF = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_SF=SNWD_SF+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_SF= SNWD_SF/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "PRCP_NYC = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_NYC=PRCP_NYC+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_NYC= PRCP_NYC/count\n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_ATL = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_ATL=PRCP_ATL+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_ATL= PRCP_ATL/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_CH = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_CH=PRCP_CH+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_CH= PRCP_CH/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_LA = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_LA=PRCP_LA+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_LA= PRCP_LA/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_SD = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_SD=PRCP_SD+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_SD= PRCP_SD/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_SF = [0 for x in range(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_SF=PRCP_SF+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_SF= PRCP_SF/count \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"TMAX_ATL\"]=TMAX_AVG_ATL\n",
    "df[\"TMAX_NYC\"]=TMAX_AVG_NYC\n",
    "df[\"TMAX_CH\"]=TMAX_AVG_CH\n",
    "df[\"TMAX_LA\"]=TMAX_AVG_LA\n",
    "df[\"TMAX_SD\"]=TMAX_AVG_SD\n",
    "df[\"TMAX_SF\"]=TMAX_AVG_SF\n",
    "\n",
    "\n",
    "df[\"TMIN_ATL\"]=TMIN_AVG_ATL\n",
    "df[\"TMIN_NYC\"]=TMIN_AVG_NYC\n",
    "df[\"TMIN_CH\"]=TMIN_AVG_CH\n",
    "df[\"TMIN_LA\"]=TMIN_AVG_LA\n",
    "df[\"TMIN_SD\"]=TMIN_AVG_SD\n",
    "df[\"TMIN_SF\"]=TMIN_AVG_SF \n",
    "\n",
    "df[\"SNOW_ATL\"]=SNOW_AVG_ATL\n",
    "df[\"SNOW_NYC\"]=SNOW_AVG_NYC\n",
    "df[\"SNOW_CH\"]=SNOW_AVG_CH\n",
    "df[\"SNOW_LA\"]=SNOW_AVG_LA\n",
    "df[\"SNOW_SD\"]=SNOW_AVG_SD\n",
    "df[\"SNOW_SF\"]=SNOW_AVG_SF \n",
    "\n",
    "df[\"SNWD_ATL\"]=SNWD_AVG_ATL\n",
    "df[\"SNWD_NYC\"]=SNWD_AVG_NYC\n",
    "df[\"SNWD_CH\"]=SNWD_AVG_CH\n",
    "df[\"SNWD_LA\"]=SNWD_AVG_LA\n",
    "df[\"SNWD_SD\"]=SNWD_AVG_SD\n",
    "df[\"SNWD_SF\"]=SNWD_AVG_SF \n",
    "\n",
    "df[\"PRCP_ATL\"]=PRCP_AVG_ATL\n",
    "df[\"PRCP_NYC\"]=PRCP_AVG_NYC\n",
    "df[\"PRCP_CH\"]=PRCP_AVG_CH\n",
    "df[\"PRCP_LA\"]=PRCP_AVG_LA\n",
    "df[\"PRCP_SD\"]=PRCP_AVG_SD\n",
    "df[\"PRCP_SF\"]=PRCP_AVG_SF \n",
    "\n",
    "df[\"SUN_ATL\"]=df_final[\"ATL_sunlight\"]\n",
    "df[\"SUN_NYC\"]=df_final[\"NYC_sunlight\"]\n",
    "df[\"SUN_LA\"]=df_final[\"LA_sunlight\"]\n",
    "df[\"SUN_CH\"]=df_final[\"CH_sunlight\"]\n",
    "df[\"SUN_SD\"]=df_final[\"SD_sunlight\"]\n",
    "df[\"SUN_SF\"]=df_final[\"SF_sunlight\"]\n",
    "\n",
    "##Adding day column##\n",
    "from datetime import date, datetime\n",
    "import calendar\n",
    "date.today().strftime(\"%A\")\n",
    "dx = {}\n",
    "for date in df_final[\"DATE\"]:\n",
    "        dx[date] = date.strftime(\"%A\")\n",
    "import collections\n",
    "dx = collections.OrderedDict(sorted(dx.items()))\n",
    "df_final[\"DAY\"] = dx.values()\n",
    "#df[\"DAY\"] = df_final[\"DAY\"]\n",
    "#df_final[\"DAY\"] = df_final[\"DAY\"].astype('category')\n",
    "df = pd.concat([df, pd.get_dummies(df_final[\"DAY\"])],axis =1) \n",
    "####\n",
    "\n",
    "#df = pd.concat([df, df_final[\"DAY\"]], axis=1)\n",
    "\n",
    "df[\"PreWalMart\"]= (-np.log(df_final[\"PREOPEN_Wal-Mart Stores, Inc Common St Stock\"])+ np.log(df_final[\"PRECLOSE_Wal-Mart Stores, Inc Common St Stock\"]))*100*df_final[\"PREVOLUME_Wal-Mart Stores, Inc Common St Stock\"]  \n",
    "\n",
    "df[\"PreApple\"]= (-np.log(df_final[\"PREOPEN_Apple, Inc Stock\"])+ np.log(df_final[\"PRECLOSE_Apple, Inc Stock\"]))*100*df_final[\"PREVOLUME_Apple, Inc Stock\"]\n",
    "                                                               \n",
    "df[\"PreBoeing\"]= (-np.log(df_final[\"PREOPEN_The Boeing Company\"])+ np.log(df_final[\"PRECLOSE_The Boeing Company\"]))*100*df_final[\"PREVOLUME_The Boeing Company\"]\n",
    "\n",
    "df[\"PreFedEx\"]= (-np.log(df_final[\"PREOPEN_FedEx Corporation\"])+ np.log(df_final[\"PRECLOSE_FedEx Corporation\"]))*100*df_final[\"PREVOLUME_FedEx Corporation\"]\n",
    "\n",
    "df[\"PreIBM\"]= (-np.log(df_final[\"PREOPEN_International Business Machines Stock\"])+ np.log(df_final[\"PRECLOSE_International Business Machines Stock\"]))*100*df_final[\"PREVOLUME_International Business Machines Stock\"]\n",
    "\n",
    "df[\"WalMart\"]= (-np.log(df_final[\"OPEN_Wal-Mart Stores, Inc Common St Stock\"])+ np.log(df_final[\"CLOSE_Wal-Mart Stores, Inc Common St Stock\"]))*100*df_final[\"VOLUME_Wal-Mart Stores, Inc Common St Stock\"]  \n",
    "\n",
    "df[\"Apple\"]= (-np.log(df_final[\"OPEN_Apple, Inc Stock\"])+ np.log(df_final[\"CLOSE_Apple, Inc Stock\"]))*100*df_final[\"VOLUME_Apple, Inc Stock\"]\n",
    "                                                               \n",
    "df[\"Boeing\"]= (-np.log(df_final[\"OPEN_The Boeing Company\"])+ np.log(df_final[\"CLOSE_The Boeing Company\"]))*100*df_final[\"VOLUME_The Boeing Company\"]\n",
    "\n",
    "df[\"FedEx\"]= (-np.log(df_final[\"OPEN_FedEx Corporation\"])+ np.log(df_final[\"CLOSE_FedEx Corporation\"]))*100*df_final[\"VOLUME_FedEx Corporation\"]\n",
    "\n",
    "df[\"IBM\"]= (-np.log(df_final[\"OPEN_International Business Machines Stock\"])+ np.log(df_final[\"CLOSE_International Business Machines Stock\"]))*100*df_final[\"VOLUME_International Business Machines Stock\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMAX_ATL</th>\n",
       "      <th>TMAX_NYC</th>\n",
       "      <th>TMAX_CH</th>\n",
       "      <th>TMAX_LA</th>\n",
       "      <th>TMAX_SD</th>\n",
       "      <th>TMAX_SF</th>\n",
       "      <th>TMIN_ATL</th>\n",
       "      <th>TMIN_NYC</th>\n",
       "      <th>TMIN_CH</th>\n",
       "      <th>TMIN_LA</th>\n",
       "      <th>...</th>\n",
       "      <th>PreWalMart</th>\n",
       "      <th>PreApple</th>\n",
       "      <th>PreBoeing</th>\n",
       "      <th>PreFedEx</th>\n",
       "      <th>PreIBM</th>\n",
       "      <th>WalMart</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Boeing</th>\n",
       "      <th>FedEx</th>\n",
       "      <th>IBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>6592.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "      <td>6.592000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>227.132403</td>\n",
       "      <td>168.737015</td>\n",
       "      <td>143.326775</td>\n",
       "      <td>245.053178</td>\n",
       "      <td>263.377640</td>\n",
       "      <td>215.350190</td>\n",
       "      <td>103.188046</td>\n",
       "      <td>72.834891</td>\n",
       "      <td>35.917764</td>\n",
       "      <td>117.241459</td>\n",
       "      <td>...</td>\n",
       "      <td>2.885785e+05</td>\n",
       "      <td>1.457989e+06</td>\n",
       "      <td>4.285408e+04</td>\n",
       "      <td>3.833251e+04</td>\n",
       "      <td>9.881637e+04</td>\n",
       "      <td>4.056129e+05</td>\n",
       "      <td>-3.317235e+06</td>\n",
       "      <td>1.002284e+05</td>\n",
       "      <td>3.040846e+04</td>\n",
       "      <td>7.458836e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>81.447445</td>\n",
       "      <td>98.522020</td>\n",
       "      <td>116.458520</td>\n",
       "      <td>57.834115</td>\n",
       "      <td>67.742508</td>\n",
       "      <td>58.178059</td>\n",
       "      <td>83.669866</td>\n",
       "      <td>91.457402</td>\n",
       "      <td>104.935522</td>\n",
       "      <td>46.449852</td>\n",
       "      <td>...</td>\n",
       "      <td>2.250734e+07</td>\n",
       "      <td>4.605561e+08</td>\n",
       "      <td>1.073746e+07</td>\n",
       "      <td>5.611903e+06</td>\n",
       "      <td>2.180371e+07</td>\n",
       "      <td>2.261507e+07</td>\n",
       "      <td>4.992004e+08</td>\n",
       "      <td>1.092042e+07</td>\n",
       "      <td>5.600890e+06</td>\n",
       "      <td>2.213297e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-46.000000</td>\n",
       "      <td>-118.300000</td>\n",
       "      <td>-217.200000</td>\n",
       "      <td>70.550000</td>\n",
       "      <td>70.250000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>-182.700000</td>\n",
       "      <td>-205.000000</td>\n",
       "      <td>-316.500000</td>\n",
       "      <td>-18.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.209243e+08</td>\n",
       "      <td>-8.383154e+09</td>\n",
       "      <td>-1.822420e+08</td>\n",
       "      <td>-1.351734e+08</td>\n",
       "      <td>-6.836456e+08</td>\n",
       "      <td>-3.209243e+08</td>\n",
       "      <td>-1.678038e+10</td>\n",
       "      <td>-1.822420e+08</td>\n",
       "      <td>-1.351734e+08</td>\n",
       "      <td>-6.836456e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>167.375000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>208.900000</td>\n",
       "      <td>166.700000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>-34.600000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.164474e+06</td>\n",
       "      <td>-7.607543e+07</td>\n",
       "      <td>-2.224116e+06</td>\n",
       "      <td>-9.271167e+05</td>\n",
       "      <td>-4.282424e+06</td>\n",
       "      <td>-5.093415e+06</td>\n",
       "      <td>-7.698142e+07</td>\n",
       "      <td>-2.200577e+06</td>\n",
       "      <td>-9.350436e+05</td>\n",
       "      <td>-4.263403e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>236.950000</td>\n",
       "      <td>172.900000</td>\n",
       "      <td>154.400000</td>\n",
       "      <td>245.500000</td>\n",
       "      <td>263.450000</td>\n",
       "      <td>217.800000</td>\n",
       "      <td>108.400000</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>116.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>296.600000</td>\n",
       "      <td>256.600000</td>\n",
       "      <td>247.325000</td>\n",
       "      <td>289.925000</td>\n",
       "      <td>324.400000</td>\n",
       "      <td>261.125000</td>\n",
       "      <td>182.800000</td>\n",
       "      <td>153.300000</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>156.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.591996e+06</td>\n",
       "      <td>7.741908e+07</td>\n",
       "      <td>2.411586e+06</td>\n",
       "      <td>1.059037e+06</td>\n",
       "      <td>4.528300e+06</td>\n",
       "      <td>5.632651e+06</td>\n",
       "      <td>7.811517e+07</td>\n",
       "      <td>2.436247e+06</td>\n",
       "      <td>1.063413e+06</td>\n",
       "      <td>4.506815e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>388.900000</td>\n",
       "      <td>385.600000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>420.500000</td>\n",
       "      <td>386.200000</td>\n",
       "      <td>240.500000</td>\n",
       "      <td>265.600000</td>\n",
       "      <td>262.300000</td>\n",
       "      <td>232.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.490632e+08</td>\n",
       "      <td>7.814666e+09</td>\n",
       "      <td>1.734670e+08</td>\n",
       "      <td>7.643459e+07</td>\n",
       "      <td>2.846651e+08</td>\n",
       "      <td>6.490632e+08</td>\n",
       "      <td>7.814666e+09</td>\n",
       "      <td>1.734670e+08</td>\n",
       "      <td>7.643459e+07</td>\n",
       "      <td>2.846651e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TMAX_ATL     TMAX_NYC      TMAX_CH      TMAX_LA      TMAX_SD  \\\n",
       "count  6592.000000  6592.000000  6592.000000  6592.000000  6592.000000   \n",
       "mean    227.132403   168.737015   143.326775   245.053178   263.377640   \n",
       "std      81.447445    98.522020   116.458520    57.834115    67.742508   \n",
       "min     -46.000000  -118.300000  -217.200000    70.550000    70.250000   \n",
       "25%     167.375000    90.000000    46.100000   201.000000   208.900000   \n",
       "50%     236.950000   172.900000   154.400000   245.500000   263.450000   \n",
       "75%     296.600000   256.600000   247.325000   289.925000   324.400000   \n",
       "max     388.900000   385.600000   380.000000   425.000000   420.500000   \n",
       "\n",
       "           TMAX_SF     TMIN_ATL     TMIN_NYC      TMIN_CH      TMIN_LA  \\\n",
       "count  6592.000000  6592.000000  6592.000000  6592.000000  6592.000000   \n",
       "mean    215.350190   103.188046    72.834891    35.917764   117.241459   \n",
       "std      58.178059    83.669866    91.457402   104.935522    46.449852   \n",
       "min      44.500000  -182.700000  -205.000000  -316.500000   -18.400000   \n",
       "25%     166.700000    36.100000     4.400000   -34.600000    80.500000   \n",
       "50%     217.800000   108.400000    71.600000    38.800000   116.700000   \n",
       "75%     261.125000   182.800000   153.300000   124.500000   156.100000   \n",
       "max     386.200000   240.500000   265.600000   262.300000   232.100000   \n",
       "\n",
       "           ...         PreWalMart      PreApple     PreBoeing      PreFedEx  \\\n",
       "count      ...       6.592000e+03  6.592000e+03  6.592000e+03  6.592000e+03   \n",
       "mean       ...       2.885785e+05  1.457989e+06  4.285408e+04  3.833251e+04   \n",
       "std        ...       2.250734e+07  4.605561e+08  1.073746e+07  5.611903e+06   \n",
       "min        ...      -3.209243e+08 -8.383154e+09 -1.822420e+08 -1.351734e+08   \n",
       "25%        ...      -5.164474e+06 -7.607543e+07 -2.224116e+06 -9.271167e+05   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       5.591996e+06  7.741908e+07  2.411586e+06  1.059037e+06   \n",
       "max        ...       6.490632e+08  7.814666e+09  1.734670e+08  7.643459e+07   \n",
       "\n",
       "             PreIBM       WalMart         Apple        Boeing         FedEx  \\\n",
       "count  6.592000e+03  6.592000e+03  6.592000e+03  6.592000e+03  6.592000e+03   \n",
       "mean   9.881637e+04  4.056129e+05 -3.317235e+06  1.002284e+05  3.040846e+04   \n",
       "std    2.180371e+07  2.261507e+07  4.992004e+08  1.092042e+07  5.600890e+06   \n",
       "min   -6.836456e+08 -3.209243e+08 -1.678038e+10 -1.822420e+08 -1.351734e+08   \n",
       "25%   -4.282424e+06 -5.093415e+06 -7.698142e+07 -2.200577e+06 -9.350436e+05   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    4.528300e+06  5.632651e+06  7.811517e+07  2.436247e+06  1.063413e+06   \n",
       "max    2.846651e+08  6.490632e+08  7.814666e+09  1.734670e+08  7.643459e+07   \n",
       "\n",
       "                IBM  \n",
       "count  6.592000e+03  \n",
       "mean   7.458836e+04  \n",
       "std    2.213297e+07  \n",
       "min   -6.836456e+08  \n",
       "25%   -4.263403e+06  \n",
       "50%    0.000000e+00  \n",
       "75%    4.506815e+06  \n",
       "max    2.846651e+08  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"PreApple\"],how='any')\n",
    "pd.DataFrame.describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158      7321482.775955\n",
       "3203           0.000000\n",
       "3437           0.000000\n",
       "4784   -21341402.728446\n",
       "5539    31329363.885100\n",
       "             ...       \n",
       "969     -2096703.027738\n",
       "1668   -61075933.335149\n",
       "3322     2916866.991127\n",
       "1689           0.000000\n",
       "5995    -2429950.684708\n",
       "Name: WalMart, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = pd.DataFrame(df.ix[:,0:42]) #weather parameters with Pre-Walmart \n",
    "#X[\"PreApple\"] = df[\"PreApple\"]\n",
    "Y = pd.DataFrame(df.ix[:,46:47]) #stock data for Walmart \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y.ix[:,0], test_size=0.2, random_state=3)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'degree': 2, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###UPDATE: Need to get Gridsearch to stop timing out\n",
    "param = {'kernel':['rbf'], 'C':[.01,10,1000],'gamma':[.0001, .001,.01,.1],'degree':[2,3,4]}\n",
    "#param = {'kernel':['poly'], 'C':[.01,10,1000],'degree':[2,3]}\n",
    "\n",
    "regressor = SVR()\n",
    "clf = GridSearchCV(regressor,param,scoring='mean_absolute_error',n_jobs=4).fit(X_train,y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: -0.0001\n"
     ]
    }
   ],
   "source": [
    "regressor.set_params(**clf.best_params_)\n",
    "regressor.fit(X_train, y_train)\n",
    "pred = regressor.predict(X_test)\n",
    "acc = regressor.score(X_test, y_test)\n",
    "print('ACC: %.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
