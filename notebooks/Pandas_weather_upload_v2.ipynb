{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Weather DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate station data by distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "cities = [\"ATL_stations\",\"CH_stations\",\"LA_stations\",\"NYC_stations\",\"SD_stations\",\"SF_stations\"]\n",
    "#Aggregate Station Location tuples \n",
    "stations_data = pd.DataFrame()\n",
    "for city in cities:\n",
    "    path = 'station_locations/%s.txt' % city\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True,header=None,error_bad_lines=False)\n",
    "        frame['city'] = city\n",
    "        stations_data = stations_data.append(frame,ignore_index=True)\n",
    "stations_data = stations_data.rename(columns={0:\"distance\",1:\"station_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ATLshortlist = stations_data[(stations_data.city == \"ATL_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "CHshortlist = stations_data[(stations_data.city == \"CH_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "LAshortlist = stations_data[(stations_data.city == \"LA_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "NYCshortlist = stations_data[(stations_data.city == \"NYC_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "SDshortlist = stations_data[(stations_data.city == \"SD_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "SFshortlist = stations_data[(stations_data.city == \"SF_stations\") & (stations_data.distance <= 100)][['station_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and Load Data \n",
    "###### Merge datasets from each station with PARAM_STATION-NAME as default column header\n",
    "##### Process results in 10 stations per city\n",
    "##### UPDATE: Frame.query removes scrappy data (missing data will still exist for some!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######ATL Weather######\n",
    "ATL_stations = [];\n",
    "ATL_weather = pd.DataFrame()\n",
    "for station in ATLshortlist['station_name']:\n",
    "    path = 'ATL/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12650:\n",
    "            ATL_stations.append(station);\n",
    "            if ATL_weather.empty:\n",
    "                ATL_weather = ATL_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                ATL_weather = ATL_weather.merge(frame, on='DATE', how='outer', suffixes=('',''))\n",
    "ATL_weather = ATL_weather.groupby('DATE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######CH Weather######\n",
    "CH_stations = [];\n",
    "CH_weather = pd.DataFrame()\n",
    "for station in CHshortlist['station_name']:\n",
    "    path = 'CH/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12764:\n",
    "            CH_stations.append(station)\n",
    "            if CH_weather.empty:\n",
    "                CH_weather = CH_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                CH_weather = CH_weather.merge(frame, on='DATE', how='outer', suffixes=('',''))\n",
    "CH_weather = CH_weather.groupby('DATE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######NYC Weather######\n",
    "NYC_stations = [];\n",
    "NYC_weather = pd.DataFrame()\n",
    "for station in NYCshortlist['station_name']:\n",
    "    path = 'NYC/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12700:\n",
    "            NYC_stations.append(station)\n",
    "            if NYC_weather.empty:\n",
    "                NYC_weather = NYC_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                NYC_weather = NYC_weather.merge(frame, on='DATE', how='outer', suffixes=('',''))\n",
    "NYC_weather = NYC_weather.groupby('DATE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######LA Weather######\n",
    "LA_stations = [];\n",
    "LA_weather = pd.DataFrame()\n",
    "for station in LAshortlist['station_name']:\n",
    "    path = 'LA/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12600: \n",
    "            LA_stations.append(station)\n",
    "            if LA_weather.empty:\n",
    "                LA_weather = LA_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                LA_weather = LA_weather.merge(frame, on='DATE', how='outer', suffixes=('',''))\n",
    "LA_weather = LA_weather.groupby('DATE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######SF Weather######\n",
    "SF_stations = [];\n",
    "SF_weather = pd.DataFrame()\n",
    "for station in SFshortlist['station_name']:\n",
    "    path = 'SF/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12784: \n",
    "            SF_stations.append(station)\n",
    "            if SF_weather.empty:\n",
    "                SF_weather = SF_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                SF_weather = SF_weather.merge(frame, on='DATE', how='outer', suffixes=('',''))\n",
    "SF_weather = SF_weather.groupby('DATE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######SD Weather######\n",
    "SD_stations = [];\n",
    "SD_weather = pd.DataFrame()\n",
    "for station in SDshortlist['station_name']:\n",
    "    path = 'SD/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12600: \n",
    "            SD_stations.append(station)\n",
    "            if SD_weather.empty:\n",
    "                SD_weather = SD_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                SD_weather = SD_weather.merge(frame, on='DATE', how='outer', suffixes=('',''))\n",
    "SD_weather = SD_weather.groupby('DATE').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Logger\n",
    "##### True indicates a missing data row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City stations missing data\n",
      "Station USC00300889\n",
      "False    12747\n",
      "True        37\n",
      "dtype: int64\n",
      "\n",
      "Station USC00305426\n",
      "False    12782\n",
      "True         2\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014732\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094728\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094745\n",
      "False    12691\n",
      "True        93\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094789\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USC00283951\n",
      "False    12762\n",
      "True        22\n",
      "dtype: int64\n",
      "\n",
      "Station USC00286055\n",
      "False    12781\n",
      "True         3\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014734\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00093730\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Atlanta stations missing data\n",
      "Station USC00092283\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USC00092485\n",
      "False    12766\n",
      "True        18\n",
      "dtype: int64\n",
      "\n",
      "Station USC00093060\n",
      "False    12779\n",
      "True         5\n",
      "dtype: int64\n",
      "\n",
      "Station USC00093621\n",
      "False    12749\n",
      "True        35\n",
      "dtype: int64\n",
      "\n",
      "Station USW00003813\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00013873\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00013874\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00093842\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USC00018469\n",
      "False    12653\n",
      "True       131\n",
      "dtype: int64\n",
      "\n",
      "Station USW00013871\n",
      "False    12781\n",
      "True         3\n",
      "dtype: int64\n",
      "\n",
      "San Francisco stations missing data\n",
      "Station USC00043578\n",
      "False    12783\n",
      "True         1\n",
      "dtype: int64\n",
      "\n",
      "Station USC00045795\n",
      "False    12781\n",
      "True         3\n",
      "dtype: int64\n",
      "\n",
      "Station USC00047916\n",
      "False    12782\n",
      "True         2\n",
      "dtype: int64\n",
      "\n",
      "Station USC00049742\n",
      "False    12781\n",
      "True         3\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023232\n",
      "False    12766\n",
      "True        18\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023233\n",
      "False    12767\n",
      "True        17\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023234\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023237\n",
      "False    12783\n",
      "True         1\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023271\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023272\n",
      "False    12782\n",
      "True         2\n",
      "dtype: int64\n",
      "\n",
      "San Diego stations missing data\n",
      "Station USC00040983\n",
      "False    12720\n",
      "True        64\n",
      "dtype: int64\n",
      "\n",
      "Station USC00042239\n",
      "False    12585\n",
      "True       199\n",
      "dtype: int64\n",
      "\n",
      "Station USC00042713\n",
      "False    12703\n",
      "True        81\n",
      "dtype: int64\n",
      "\n",
      "Station USC00043914\n",
      "False    12604\n",
      "True       180\n",
      "dtype: int64\n",
      "\n",
      "Station USC00044223\n",
      "False    12693\n",
      "True        91\n",
      "dtype: int64\n",
      "\n",
      "Station USC00047888\n",
      "False    12622\n",
      "True       162\n",
      "dtype: int64\n",
      "\n",
      "Station USW00003104\n",
      "False    12642\n",
      "True       142\n",
      "dtype: int64\n",
      "\n",
      "Station USW00003164\n",
      "False    12643\n",
      "True       141\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023129\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00023188\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Los Angeles stations missing data\n",
      "Station USC00041194\n",
      "False    12602\n",
      "True       182\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USC00046624\n",
      "False    12650\n",
      "True       134\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USC00046719\n",
      "False    12640\n",
      "True       144\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USC00047888\n",
      "False    12622\n",
      "True       162\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USC00049152\n",
      "False    12722\n",
      "True        62\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USC00049785\n",
      "False    12740\n",
      "True        44\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USW00003159\n",
      "False    12637\n",
      "True       147\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USW00023129\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USW00023174\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USW00093134\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Chicago stations missing data\n",
      "Station USC00472869\n",
      "False    12781\n",
      "True         3\n",
      "dtype: int64\n",
      "\n",
      "Station USC00473058\n",
      "False    12752\n",
      "True        32\n",
      "dtype: int64\n",
      "\n",
      "Station USC00473453\n",
      "False    12755\n",
      "True        29\n",
      "dtype: int64\n",
      "\n",
      "Station USC00476200\n",
      "False    12779\n",
      "True         5\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014839\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USC00125174\n",
      "False    12752\n",
      "True        32\n",
      "dtype: int64\n",
      "\n",
      "Station USW00014848\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USC00113262\n",
      "False    12753\n",
      "True        31\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094822\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n",
      "Station USW00094846\n",
      "False    12784\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"New York City stations missing data\")\n",
    "for station in NYC_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(NYC_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Atlanta stations missing data\")\n",
    "for station in ATL_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(ATL_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "    \n",
    "print(\"San Francisco stations missing data\")\n",
    "for station in SF_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(SF_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"San Diego stations missing data\")\n",
    "for station in SD_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(SD_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Los Angeles stations missing data\")\n",
    "for station in LA_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(LA_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "    print(\"Chicago stations missing data\")\n",
    "for station in CH_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(CH_weather)['TMIN_'+station].value_counts())\n",
    "    print()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
