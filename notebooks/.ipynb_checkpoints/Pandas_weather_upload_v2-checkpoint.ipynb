{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Weather DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate station data by distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 33: expected 9 fields, saw 10\n",
      "Skipping line 44: expected 9 fields, saw 10\n",
      "Skipping line 45: expected 9 fields, saw 10\n",
      "Skipping line 53: expected 9 fields, saw 10\n",
      "Skipping line 56: expected 9 fields, saw 10\n",
      "Skipping line 60: expected 9 fields, saw 10\n",
      "Skipping line 83: expected 9 fields, saw 10\n",
      "Skipping line 84: expected 9 fields, saw 10\n",
      "Skipping line 86: expected 9 fields, saw 10\n",
      "Skipping line 90: expected 9 fields, saw 10\n",
      "Skipping line 111: expected 9 fields, saw 10\n",
      "Skipping line 112: expected 9 fields, saw 10\n",
      "Skipping line 114: expected 9 fields, saw 10\n",
      "Skipping line 115: expected 9 fields, saw 10\n",
      "Skipping line 118: expected 9 fields, saw 10\n",
      "Skipping line 119: expected 9 fields, saw 10\n",
      "Skipping line 125: expected 9 fields, saw 10\n",
      "Skipping line 127: expected 9 fields, saw 10\n",
      "Skipping line 138: expected 9 fields, saw 10\n",
      "Skipping line 140: expected 9 fields, saw 10\n",
      "Skipping line 144: expected 9 fields, saw 10\n",
      "Skipping line 146: expected 9 fields, saw 10\n",
      "Skipping line 153: expected 9 fields, saw 10\n",
      "Skipping line 154: expected 9 fields, saw 10\n",
      "Skipping line 155: expected 9 fields, saw 10\n",
      "Skipping line 158: expected 9 fields, saw 10\n",
      "Skipping line 165: expected 9 fields, saw 10\n",
      "Skipping line 169: expected 9 fields, saw 10\n",
      "Skipping line 174: expected 9 fields, saw 10\n",
      "Skipping line 179: expected 9 fields, saw 10\n",
      "Skipping line 183: expected 9 fields, saw 10\n",
      "Skipping line 190: expected 9 fields, saw 10\n",
      "Skipping line 194: expected 9 fields, saw 10\n",
      "Skipping line 197: expected 9 fields, saw 10\n",
      "Skipping line 201: expected 9 fields, saw 10\n",
      "Skipping line 202: expected 9 fields, saw 10\n",
      "Skipping line 203: expected 9 fields, saw 10\n",
      "Skipping line 204: expected 9 fields, saw 10\n",
      "Skipping line 207: expected 9 fields, saw 10\n",
      "Skipping line 211: expected 9 fields, saw 10\n",
      "Skipping line 242: expected 9 fields, saw 10\n",
      "Skipping line 252: expected 9 fields, saw 10\n",
      "Skipping line 255: expected 9 fields, saw 10\n",
      "Skipping line 260: expected 9 fields, saw 10\n",
      "Skipping line 262: expected 9 fields, saw 10\n",
      "Skipping line 263: expected 9 fields, saw 10\n",
      "Skipping line 265: expected 9 fields, saw 10\n",
      "Skipping line 266: expected 9 fields, saw 10\n",
      "Skipping line 268: expected 9 fields, saw 10\n",
      "Skipping line 270: expected 9 fields, saw 10\n",
      "Skipping line 274: expected 9 fields, saw 10\n",
      "Skipping line 333: expected 9 fields, saw 10\n",
      "Skipping line 335: expected 9 fields, saw 10\n",
      "Skipping line 368: expected 9 fields, saw 10\n",
      "Skipping line 369: expected 9 fields, saw 10\n",
      "Skipping line 386: expected 9 fields, saw 10\n",
      "Skipping line 393: expected 9 fields, saw 10\n",
      "Skipping line 396: expected 9 fields, saw 10\n",
      "Skipping line 397: expected 9 fields, saw 10\n",
      "Skipping line 398: expected 9 fields, saw 10\n",
      "Skipping line 399: expected 9 fields, saw 10\n",
      "Skipping line 400: expected 9 fields, saw 10\n",
      "Skipping line 401: expected 9 fields, saw 10\n",
      "Skipping line 402: expected 9 fields, saw 10\n",
      "Skipping line 409: expected 9 fields, saw 10\n",
      "Skipping line 412: expected 9 fields, saw 10\n",
      "Skipping line 414: expected 9 fields, saw 10\n",
      "Skipping line 415: expected 9 fields, saw 10\n",
      "Skipping line 416: expected 9 fields, saw 10\n",
      "Skipping line 422: expected 9 fields, saw 10\n",
      "Skipping line 437: expected 9 fields, saw 10\n",
      "Skipping line 447: expected 9 fields, saw 10\n",
      "Skipping line 448: expected 9 fields, saw 10\n",
      "Skipping line 468: expected 9 fields, saw 10\n",
      "Skipping line 511: expected 9 fields, saw 10\n",
      "Skipping line 535: expected 9 fields, saw 10\n",
      "Skipping line 546: expected 9 fields, saw 10\n",
      "Skipping line 561: expected 9 fields, saw 10\n",
      "Skipping line 579: expected 9 fields, saw 10\n",
      "Skipping line 614: expected 9 fields, saw 11\n",
      "Skipping line 617: expected 9 fields, saw 10\n",
      "Skipping line 640: expected 9 fields, saw 12\n",
      "Skipping line 642: expected 9 fields, saw 10\n",
      "Skipping line 643: expected 9 fields, saw 11\n",
      "Skipping line 645: expected 9 fields, saw 10\n",
      "Skipping line 646: expected 9 fields, saw 11\n",
      "Skipping line 647: expected 9 fields, saw 11\n",
      "Skipping line 653: expected 9 fields, saw 11\n",
      "Skipping line 654: expected 9 fields, saw 12\n",
      "Skipping line 669: expected 9 fields, saw 10\n",
      "Skipping line 671: expected 9 fields, saw 10\n",
      "Skipping line 684: expected 9 fields, saw 10\n",
      "Skipping line 685: expected 9 fields, saw 10\n",
      "Skipping line 689: expected 9 fields, saw 10\n",
      "Skipping line 690: expected 9 fields, saw 10\n",
      "Skipping line 691: expected 9 fields, saw 10\n",
      "Skipping line 692: expected 9 fields, saw 10\n",
      "Skipping line 694: expected 9 fields, saw 10\n",
      "Skipping line 695: expected 9 fields, saw 10\n",
      "Skipping line 700: expected 9 fields, saw 11\n",
      "Skipping line 720: expected 9 fields, saw 10\n",
      "Skipping line 721: expected 9 fields, saw 10\n",
      "Skipping line 724: expected 9 fields, saw 10\n",
      "Skipping line 734: expected 9 fields, saw 11\n",
      "Skipping line 735: expected 9 fields, saw 11\n",
      "Skipping line 736: expected 9 fields, saw 10\n",
      "\n",
      "Skipping line 151: expected 10 fields, saw 11\n",
      "Skipping line 229: expected 10 fields, saw 12\n",
      "Skipping line 231: expected 10 fields, saw 12\n",
      "Skipping line 363: expected 10 fields, saw 12\n",
      "Skipping line 372: expected 10 fields, saw 12\n",
      "Skipping line 448: expected 10 fields, saw 11\n",
      "Skipping line 496: expected 10 fields, saw 11\n",
      "Skipping line 497: expected 10 fields, saw 12\n",
      "Skipping line 524: expected 10 fields, saw 11\n",
      "Skipping line 533: expected 10 fields, saw 11\n",
      "Skipping line 541: expected 10 fields, saw 11\n",
      "Skipping line 554: expected 10 fields, saw 11\n",
      "Skipping line 586: expected 10 fields, saw 11\n",
      "Skipping line 826: expected 10 fields, saw 11\n",
      "Skipping line 1057: expected 10 fields, saw 11\n",
      "Skipping line 1062: expected 10 fields, saw 11\n",
      "Skipping line 1064: expected 10 fields, saw 11\n",
      "Skipping line 1124: expected 10 fields, saw 11\n",
      "Skipping line 1170: expected 10 fields, saw 11\n",
      "Skipping line 1202: expected 10 fields, saw 11\n",
      "Skipping line 1203: expected 10 fields, saw 11\n",
      "Skipping line 1204: expected 10 fields, saw 11\n",
      "\n",
      "Skipping line 4: expected 10 fields, saw 11\n",
      "Skipping line 5: expected 10 fields, saw 11\n",
      "Skipping line 28: expected 10 fields, saw 11\n",
      "Skipping line 95: expected 10 fields, saw 12\n",
      "Skipping line 156: expected 10 fields, saw 11\n",
      "Skipping line 162: expected 10 fields, saw 11\n",
      "Skipping line 166: expected 10 fields, saw 11\n",
      "Skipping line 184: expected 10 fields, saw 11\n",
      "Skipping line 192: expected 10 fields, saw 11\n",
      "Skipping line 209: expected 10 fields, saw 11\n",
      "Skipping line 246: expected 10 fields, saw 11\n",
      "Skipping line 266: expected 10 fields, saw 12\n",
      "Skipping line 270: expected 10 fields, saw 11\n",
      "Skipping line 294: expected 10 fields, saw 11\n",
      "Skipping line 312: expected 10 fields, saw 11\n",
      "Skipping line 343: expected 10 fields, saw 11\n",
      "Skipping line 345: expected 10 fields, saw 11\n",
      "Skipping line 362: expected 10 fields, saw 11\n",
      "Skipping line 363: expected 10 fields, saw 11\n",
      "Skipping line 364: expected 10 fields, saw 12\n",
      "Skipping line 507: expected 10 fields, saw 11\n",
      "Skipping line 516: expected 10 fields, saw 11\n",
      "Skipping line 520: expected 10 fields, saw 11\n",
      "Skipping line 522: expected 10 fields, saw 11\n",
      "Skipping line 527: expected 10 fields, saw 11\n",
      "Skipping line 530: expected 10 fields, saw 11\n",
      "Skipping line 531: expected 10 fields, saw 11\n",
      "Skipping line 532: expected 10 fields, saw 12\n",
      "Skipping line 543: expected 10 fields, saw 11\n",
      "Skipping line 544: expected 10 fields, saw 11\n",
      "\n",
      "Skipping line 16: expected 10 fields, saw 11\n",
      "Skipping line 217: expected 10 fields, saw 11\n",
      "Skipping line 222: expected 10 fields, saw 11\n",
      "Skipping line 223: expected 10 fields, saw 11\n",
      "Skipping line 224: expected 10 fields, saw 11\n",
      "Skipping line 228: expected 10 fields, saw 11\n",
      "Skipping line 230: expected 10 fields, saw 13\n",
      "Skipping line 232: expected 10 fields, saw 12\n",
      "Skipping line 233: expected 10 fields, saw 11\n",
      "Skipping line 237: expected 10 fields, saw 11\n",
      "Skipping line 239: expected 10 fields, saw 11\n",
      "Skipping line 241: expected 10 fields, saw 11\n",
      "Skipping line 245: expected 10 fields, saw 11\n",
      "Skipping line 246: expected 10 fields, saw 11\n",
      "Skipping line 262: expected 10 fields, saw 11\n",
      "Skipping line 270: expected 10 fields, saw 11\n",
      "Skipping line 274: expected 10 fields, saw 11\n",
      "Skipping line 282: expected 10 fields, saw 11\n",
      "Skipping line 285: expected 10 fields, saw 11\n",
      "Skipping line 298: expected 10 fields, saw 11\n",
      "Skipping line 301: expected 10 fields, saw 11\n",
      "Skipping line 314: expected 10 fields, saw 11\n",
      "Skipping line 315: expected 10 fields, saw 11\n",
      "Skipping line 368: expected 10 fields, saw 11\n",
      "Skipping line 370: expected 10 fields, saw 11\n",
      "Skipping line 373: expected 10 fields, saw 11\n",
      "Skipping line 375: expected 10 fields, saw 11\n",
      "Skipping line 379: expected 10 fields, saw 11\n",
      "Skipping line 381: expected 10 fields, saw 11\n",
      "Skipping line 384: expected 10 fields, saw 11\n",
      "Skipping line 392: expected 10 fields, saw 11\n",
      "Skipping line 401: expected 10 fields, saw 11\n",
      "Skipping line 425: expected 10 fields, saw 11\n",
      "Skipping line 438: expected 10 fields, saw 11\n",
      "Skipping line 441: expected 10 fields, saw 11\n",
      "Skipping line 442: expected 10 fields, saw 11\n",
      "Skipping line 446: expected 10 fields, saw 11\n",
      "Skipping line 456: expected 10 fields, saw 11\n",
      "Skipping line 460: expected 10 fields, saw 11\n",
      "Skipping line 465: expected 10 fields, saw 11\n",
      "Skipping line 467: expected 10 fields, saw 11\n",
      "Skipping line 468: expected 10 fields, saw 12\n",
      "Skipping line 471: expected 10 fields, saw 11\n",
      "Skipping line 473: expected 10 fields, saw 11\n",
      "Skipping line 480: expected 10 fields, saw 11\n",
      "Skipping line 481: expected 10 fields, saw 12\n",
      "Skipping line 489: expected 10 fields, saw 11\n",
      "Skipping line 494: expected 10 fields, saw 11\n",
      "Skipping line 499: expected 10 fields, saw 11\n",
      "Skipping line 500: expected 10 fields, saw 11\n",
      "Skipping line 503: expected 10 fields, saw 11\n",
      "Skipping line 507: expected 10 fields, saw 11\n",
      "Skipping line 628: expected 10 fields, saw 11\n",
      "Skipping line 653: expected 10 fields, saw 11\n",
      "Skipping line 717: expected 10 fields, saw 11\n",
      "Skipping line 718: expected 10 fields, saw 11\n",
      "\n",
      "Skipping line 3: expected 9 fields, saw 10\n",
      "Skipping line 6: expected 9 fields, saw 10\n",
      "Skipping line 7: expected 9 fields, saw 10\n",
      "Skipping line 9: expected 9 fields, saw 10\n",
      "Skipping line 10: expected 9 fields, saw 10\n",
      "Skipping line 11: expected 9 fields, saw 10\n",
      "Skipping line 13: expected 9 fields, saw 10\n",
      "Skipping line 14: expected 9 fields, saw 10\n",
      "Skipping line 15: expected 9 fields, saw 10\n",
      "Skipping line 16: expected 9 fields, saw 10\n",
      "Skipping line 17: expected 9 fields, saw 10\n",
      "Skipping line 19: expected 9 fields, saw 10\n",
      "Skipping line 20: expected 9 fields, saw 10\n",
      "Skipping line 22: expected 9 fields, saw 10\n",
      "Skipping line 24: expected 9 fields, saw 10\n",
      "Skipping line 28: expected 9 fields, saw 10\n",
      "Skipping line 29: expected 9 fields, saw 10\n",
      "Skipping line 33: expected 9 fields, saw 10\n",
      "Skipping line 34: expected 9 fields, saw 11\n",
      "Skipping line 39: expected 9 fields, saw 10\n",
      "Skipping line 46: expected 9 fields, saw 10\n",
      "Skipping line 50: expected 9 fields, saw 10\n",
      "Skipping line 52: expected 9 fields, saw 10\n",
      "Skipping line 54: expected 9 fields, saw 10\n",
      "Skipping line 56: expected 9 fields, saw 10\n",
      "Skipping line 58: expected 9 fields, saw 10\n",
      "Skipping line 67: expected 9 fields, saw 10\n",
      "Skipping line 69: expected 9 fields, saw 10\n",
      "Skipping line 72: expected 9 fields, saw 10\n",
      "Skipping line 74: expected 9 fields, saw 12\n",
      "Skipping line 76: expected 9 fields, saw 10\n",
      "Skipping line 81: expected 9 fields, saw 10\n",
      "Skipping line 82: expected 9 fields, saw 10\n",
      "Skipping line 85: expected 9 fields, saw 10\n",
      "Skipping line 86: expected 9 fields, saw 10\n",
      "Skipping line 87: expected 9 fields, saw 10\n",
      "Skipping line 89: expected 9 fields, saw 10\n",
      "Skipping line 90: expected 9 fields, saw 10\n",
      "Skipping line 95: expected 9 fields, saw 11\n",
      "Skipping line 101: expected 9 fields, saw 10\n",
      "Skipping line 106: expected 9 fields, saw 10\n",
      "Skipping line 115: expected 9 fields, saw 10\n",
      "Skipping line 118: expected 9 fields, saw 10\n",
      "Skipping line 131: expected 9 fields, saw 12\n",
      "Skipping line 132: expected 9 fields, saw 10\n",
      "Skipping line 134: expected 9 fields, saw 10\n",
      "Skipping line 137: expected 9 fields, saw 10\n",
      "Skipping line 145: expected 9 fields, saw 10\n",
      "Skipping line 153: expected 9 fields, saw 10\n",
      "Skipping line 157: expected 9 fields, saw 10\n",
      "Skipping line 158: expected 9 fields, saw 10\n",
      "Skipping line 159: expected 9 fields, saw 11\n",
      "Skipping line 175: expected 9 fields, saw 10\n",
      "Skipping line 179: expected 9 fields, saw 10\n",
      "Skipping line 182: expected 9 fields, saw 10\n",
      "Skipping line 205: expected 9 fields, saw 10\n",
      "Skipping line 210: expected 9 fields, saw 10\n",
      "Skipping line 217: expected 9 fields, saw 10\n",
      "Skipping line 220: expected 9 fields, saw 10\n",
      "Skipping line 222: expected 9 fields, saw 10\n",
      "Skipping line 230: expected 9 fields, saw 10\n",
      "Skipping line 232: expected 9 fields, saw 10\n",
      "Skipping line 242: expected 9 fields, saw 10\n",
      "Skipping line 258: expected 9 fields, saw 10\n",
      "Skipping line 260: expected 9 fields, saw 11\n",
      "Skipping line 266: expected 9 fields, saw 10\n",
      "Skipping line 267: expected 9 fields, saw 10\n",
      "Skipping line 269: expected 9 fields, saw 10\n",
      "Skipping line 270: expected 9 fields, saw 11\n",
      "Skipping line 271: expected 9 fields, saw 11\n",
      "Skipping line 273: expected 9 fields, saw 10\n",
      "Skipping line 275: expected 9 fields, saw 10\n",
      "Skipping line 283: expected 9 fields, saw 10\n",
      "Skipping line 284: expected 9 fields, saw 10\n",
      "Skipping line 285: expected 9 fields, saw 10\n",
      "Skipping line 286: expected 9 fields, saw 10\n",
      "Skipping line 292: expected 9 fields, saw 10\n",
      "Skipping line 300: expected 9 fields, saw 10\n",
      "Skipping line 307: expected 9 fields, saw 10\n",
      "Skipping line 315: expected 9 fields, saw 10\n",
      "Skipping line 321: expected 9 fields, saw 10\n",
      "Skipping line 328: expected 9 fields, saw 10\n",
      "Skipping line 329: expected 9 fields, saw 10\n",
      "Skipping line 336: expected 9 fields, saw 10\n",
      "Skipping line 340: expected 9 fields, saw 11\n",
      "Skipping line 343: expected 9 fields, saw 10\n",
      "Skipping line 345: expected 9 fields, saw 12\n",
      "Skipping line 346: expected 9 fields, saw 10\n",
      "Skipping line 347: expected 9 fields, saw 11\n",
      "Skipping line 348: expected 9 fields, saw 10\n",
      "Skipping line 351: expected 9 fields, saw 11\n",
      "Skipping line 352: expected 9 fields, saw 10\n",
      "Skipping line 354: expected 9 fields, saw 11\n",
      "Skipping line 358: expected 9 fields, saw 11\n",
      "Skipping line 359: expected 9 fields, saw 10\n",
      "Skipping line 362: expected 9 fields, saw 10\n",
      "Skipping line 363: expected 9 fields, saw 11\n",
      "\n",
      "Skipping line 2: expected 9 fields, saw 10\n",
      "Skipping line 3: expected 9 fields, saw 10\n",
      "Skipping line 8: expected 9 fields, saw 10\n",
      "Skipping line 17: expected 9 fields, saw 10\n",
      "Skipping line 18: expected 9 fields, saw 10\n",
      "Skipping line 28: expected 9 fields, saw 10\n",
      "Skipping line 29: expected 9 fields, saw 10\n",
      "Skipping line 32: expected 9 fields, saw 10\n",
      "Skipping line 35: expected 9 fields, saw 10\n",
      "Skipping line 39: expected 9 fields, saw 10\n",
      "Skipping line 41: expected 9 fields, saw 10\n",
      "Skipping line 45: expected 9 fields, saw 10\n",
      "Skipping line 47: expected 9 fields, saw 10\n",
      "Skipping line 48: expected 9 fields, saw 10\n",
      "Skipping line 49: expected 9 fields, saw 10\n",
      "Skipping line 52: expected 9 fields, saw 10\n",
      "Skipping line 53: expected 9 fields, saw 10\n",
      "Skipping line 55: expected 9 fields, saw 10\n",
      "Skipping line 56: expected 9 fields, saw 10\n",
      "Skipping line 58: expected 9 fields, saw 10\n",
      "Skipping line 59: expected 9 fields, saw 10\n",
      "Skipping line 60: expected 9 fields, saw 10\n",
      "Skipping line 64: expected 9 fields, saw 11\n",
      "Skipping line 65: expected 9 fields, saw 10\n",
      "Skipping line 68: expected 9 fields, saw 10\n",
      "Skipping line 70: expected 9 fields, saw 11\n",
      "Skipping line 73: expected 9 fields, saw 11\n",
      "Skipping line 74: expected 9 fields, saw 10\n",
      "Skipping line 76: expected 9 fields, saw 10\n",
      "Skipping line 77: expected 9 fields, saw 10\n",
      "Skipping line 84: expected 9 fields, saw 10\n",
      "Skipping line 85: expected 9 fields, saw 10\n",
      "Skipping line 86: expected 9 fields, saw 10\n",
      "Skipping line 103: expected 9 fields, saw 10\n",
      "Skipping line 105: expected 9 fields, saw 10\n",
      "Skipping line 107: expected 9 fields, saw 10\n",
      "Skipping line 110: expected 9 fields, saw 10\n",
      "Skipping line 111: expected 9 fields, saw 10\n",
      "Skipping line 112: expected 9 fields, saw 10\n",
      "Skipping line 113: expected 9 fields, saw 10\n",
      "Skipping line 114: expected 9 fields, saw 10\n",
      "Skipping line 116: expected 9 fields, saw 10\n",
      "Skipping line 117: expected 9 fields, saw 10\n",
      "Skipping line 118: expected 9 fields, saw 10\n",
      "Skipping line 119: expected 9 fields, saw 10\n",
      "Skipping line 120: expected 9 fields, saw 10\n",
      "Skipping line 121: expected 9 fields, saw 10\n",
      "Skipping line 122: expected 9 fields, saw 10\n",
      "Skipping line 123: expected 9 fields, saw 10\n",
      "Skipping line 124: expected 9 fields, saw 10\n",
      "Skipping line 125: expected 9 fields, saw 10\n",
      "Skipping line 127: expected 9 fields, saw 10\n",
      "Skipping line 128: expected 9 fields, saw 10\n",
      "Skipping line 129: expected 9 fields, saw 10\n",
      "Skipping line 130: expected 9 fields, saw 10\n",
      "Skipping line 131: expected 9 fields, saw 10\n",
      "Skipping line 133: expected 9 fields, saw 10\n",
      "Skipping line 134: expected 9 fields, saw 10\n",
      "Skipping line 135: expected 9 fields, saw 11\n",
      "Skipping line 137: expected 9 fields, saw 10\n",
      "Skipping line 138: expected 9 fields, saw 10\n",
      "Skipping line 139: expected 9 fields, saw 10\n",
      "Skipping line 140: expected 9 fields, saw 10\n",
      "Skipping line 141: expected 9 fields, saw 10\n",
      "Skipping line 143: expected 9 fields, saw 10\n",
      "Skipping line 144: expected 9 fields, saw 10\n",
      "Skipping line 145: expected 9 fields, saw 10\n",
      "Skipping line 146: expected 9 fields, saw 10\n",
      "Skipping line 156: expected 9 fields, saw 11\n",
      "Skipping line 157: expected 9 fields, saw 10\n",
      "Skipping line 158: expected 9 fields, saw 10\n",
      "Skipping line 159: expected 9 fields, saw 11\n",
      "Skipping line 160: expected 9 fields, saw 10\n",
      "Skipping line 161: expected 9 fields, saw 10\n",
      "Skipping line 164: expected 9 fields, saw 10\n",
      "Skipping line 165: expected 9 fields, saw 11\n",
      "Skipping line 166: expected 9 fields, saw 10\n",
      "Skipping line 167: expected 9 fields, saw 10\n",
      "Skipping line 168: expected 9 fields, saw 11\n",
      "Skipping line 170: expected 9 fields, saw 10\n",
      "Skipping line 174: expected 9 fields, saw 10\n",
      "Skipping line 177: expected 9 fields, saw 10\n",
      "Skipping line 178: expected 9 fields, saw 10\n",
      "Skipping line 187: expected 9 fields, saw 10\n",
      "Skipping line 188: expected 9 fields, saw 10\n",
      "Skipping line 192: expected 9 fields, saw 10\n",
      "Skipping line 193: expected 9 fields, saw 10\n",
      "Skipping line 195: expected 9 fields, saw 10\n",
      "Skipping line 196: expected 9 fields, saw 10\n",
      "Skipping line 197: expected 9 fields, saw 10\n",
      "Skipping line 198: expected 9 fields, saw 10\n",
      "Skipping line 199: expected 9 fields, saw 10\n",
      "Skipping line 201: expected 9 fields, saw 10\n",
      "Skipping line 206: expected 9 fields, saw 10\n",
      "Skipping line 210: expected 9 fields, saw 10\n",
      "Skipping line 214: expected 9 fields, saw 10\n",
      "Skipping line 217: expected 9 fields, saw 10\n",
      "Skipping line 218: expected 9 fields, saw 10\n",
      "Skipping line 219: expected 9 fields, saw 10\n",
      "Skipping line 222: expected 9 fields, saw 10\n",
      "Skipping line 223: expected 9 fields, saw 10\n",
      "Skipping line 224: expected 9 fields, saw 10\n",
      "Skipping line 225: expected 9 fields, saw 11\n",
      "Skipping line 227: expected 9 fields, saw 10\n",
      "Skipping line 231: expected 9 fields, saw 10\n",
      "Skipping line 232: expected 9 fields, saw 10\n",
      "Skipping line 237: expected 9 fields, saw 10\n",
      "Skipping line 243: expected 9 fields, saw 10\n",
      "Skipping line 245: expected 9 fields, saw 11\n",
      "Skipping line 249: expected 9 fields, saw 10\n",
      "Skipping line 250: expected 9 fields, saw 10\n",
      "Skipping line 253: expected 9 fields, saw 10\n",
      "Skipping line 254: expected 9 fields, saw 10\n",
      "Skipping line 256: expected 9 fields, saw 10\n",
      "Skipping line 258: expected 9 fields, saw 10\n",
      "Skipping line 260: expected 9 fields, saw 10\n",
      "Skipping line 262: expected 9 fields, saw 10\n",
      "Skipping line 264: expected 9 fields, saw 10\n",
      "Skipping line 265: expected 9 fields, saw 10\n",
      "Skipping line 267: expected 9 fields, saw 10\n",
      "Skipping line 268: expected 9 fields, saw 10\n",
      "Skipping line 269: expected 9 fields, saw 10\n",
      "Skipping line 270: expected 9 fields, saw 10\n",
      "Skipping line 289: expected 9 fields, saw 10\n",
      "Skipping line 292: expected 9 fields, saw 10\n",
      "Skipping line 304: expected 9 fields, saw 10\n",
      "Skipping line 305: expected 9 fields, saw 10\n",
      "Skipping line 307: expected 9 fields, saw 10\n",
      "Skipping line 320: expected 9 fields, saw 10\n",
      "Skipping line 341: expected 9 fields, saw 12\n",
      "Skipping line 343: expected 9 fields, saw 10\n",
      "Skipping line 369: expected 9 fields, saw 10\n",
      "Skipping line 378: expected 9 fields, saw 10\n",
      "Skipping line 385: expected 9 fields, saw 10\n",
      "Skipping line 387: expected 9 fields, saw 10\n",
      "Skipping line 389: expected 9 fields, saw 10\n",
      "Skipping line 393: expected 9 fields, saw 10\n",
      "Skipping line 399: expected 9 fields, saw 10\n",
      "Skipping line 400: expected 9 fields, saw 10\n",
      "Skipping line 402: expected 9 fields, saw 10\n",
      "Skipping line 403: expected 9 fields, saw 10\n",
      "Skipping line 418: expected 9 fields, saw 10\n",
      "Skipping line 419: expected 9 fields, saw 10\n",
      "Skipping line 424: expected 9 fields, saw 10\n",
      "Skipping line 427: expected 9 fields, saw 10\n",
      "Skipping line 452: expected 9 fields, saw 10\n",
      "Skipping line 460: expected 9 fields, saw 10\n",
      "Skipping line 461: expected 9 fields, saw 10\n",
      "Skipping line 465: expected 9 fields, saw 10\n",
      "Skipping line 467: expected 9 fields, saw 10\n",
      "Skipping line 468: expected 9 fields, saw 11\n",
      "Skipping line 470: expected 9 fields, saw 10\n",
      "Skipping line 472: expected 9 fields, saw 11\n",
      "Skipping line 475: expected 9 fields, saw 10\n",
      "Skipping line 481: expected 9 fields, saw 10\n",
      "Skipping line 491: expected 9 fields, saw 10\n",
      "Skipping line 498: expected 9 fields, saw 10\n",
      "Skipping line 504: expected 9 fields, saw 10\n",
      "Skipping line 505: expected 9 fields, saw 10\n",
      "Skipping line 506: expected 9 fields, saw 10\n",
      "Skipping line 514: expected 9 fields, saw 10\n",
      "Skipping line 528: expected 9 fields, saw 10\n",
      "Skipping line 529: expected 9 fields, saw 10\n",
      "Skipping line 546: expected 9 fields, saw 10\n",
      "Skipping line 555: expected 9 fields, saw 11\n",
      "Skipping line 556: expected 9 fields, saw 11\n",
      "Skipping line 557: expected 9 fields, saw 11\n",
      "Skipping line 558: expected 9 fields, saw 10\n",
      "Skipping line 559: expected 9 fields, saw 11\n",
      "Skipping line 560: expected 9 fields, saw 10\n",
      "Skipping line 564: expected 9 fields, saw 10\n",
      "Skipping line 569: expected 9 fields, saw 10\n",
      "Skipping line 570: expected 9 fields, saw 10\n",
      "Skipping line 581: expected 9 fields, saw 10\n",
      "Skipping line 582: expected 9 fields, saw 10\n",
      "Skipping line 583: expected 9 fields, saw 11\n",
      "Skipping line 584: expected 9 fields, saw 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "cities = [\"ATL_stations\",\"CH_stations\",\"LA_stations\",\"NYC_stations\",\"SD_stations\",\"SF_stations\"]\n",
    "#Aggregate Station Location tuples \n",
    "stations_data = pd.DataFrame()\n",
    "for city in cities:\n",
    "    path = 'station_locations/%s.txt' % city\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True,header=None,error_bad_lines=False)\n",
    "        frame['city'] = city\n",
    "        stations_data = stations_data.append(frame,ignore_index=True)\n",
    "stations_data = stations_data.rename(columns={0:\"distance\",1:\"station_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ATLshortlist = stations_data[(stations_data.city == \"ATL_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "CHshortlist = stations_data[(stations_data.city == \"CH_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "LAshortlist = stations_data[(stations_data.city == \"LA_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "NYCshortlist = stations_data[(stations_data.city == \"NYC_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "SDshortlist = stations_data[(stations_data.city == \"SD_stations\") & (stations_data.distance <= 100)][['station_name']]\n",
    "SFshortlist = stations_data[(stations_data.city == \"SF_stations\") & (stations_data.distance <= 100)][['station_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and Load Data \n",
    "###### Merge datasets from each station with PARAM_STATION-NAME as default column header\n",
    "##### Process results in 10 stations per city\n",
    "##### UPDATE: Frame.query removes scrappy data (missing data will still exist for some!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######ATL Weather######\n",
    "ATL_stations = [];\n",
    "ATL_weather = pd.DataFrame()\n",
    "for station in ATLshortlist['station_name']:\n",
    "    path = 'ATL/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12650:\n",
    "            ATL_stations.append(station);\n",
    "            if ATL_weather.empty:\n",
    "                ATL_weather = ATL_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                ATL_weather = ATL_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "ATL_weather = ATL_weather.groupby('DATE').mean()\n",
    "ATL_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######CH Weather######\n",
    "CH_stations = [];\n",
    "CH_weather = pd.DataFrame()\n",
    "for station in CHshortlist['station_name']:\n",
    "    path = 'CH/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12764:\n",
    "            CH_stations.append(station)\n",
    "            if CH_weather.empty:\n",
    "                CH_weather = CH_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                CH_weather = CH_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "CH_weather = CH_weather.groupby('DATE').mean()\n",
    "CH_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######NYC Weather######\n",
    "NYC_stations = [];\n",
    "NYC_weather = pd.DataFrame()\n",
    "for station in NYCshortlist['station_name']:\n",
    "    path = 'NYC/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12700:\n",
    "            NYC_stations.append(station)\n",
    "            if NYC_weather.empty:\n",
    "                NYC_weather = NYC_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                NYC_weather = NYC_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "NYC_weather = NYC_weather.groupby('DATE').mean()\n",
    "NYC_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######LA Weather######\n",
    "LA_stations = [];\n",
    "LA_weather = pd.DataFrame()\n",
    "for station in LAshortlist['station_name']:\n",
    "    path = 'LA/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12600: \n",
    "            LA_stations.append(station)\n",
    "            if LA_weather.empty:\n",
    "                LA_weather = LA_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                LA_weather = LA_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "LA_weather = LA_weather.groupby('DATE').mean()\n",
    "LA_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######SF Weather######\n",
    "SF_stations = [];\n",
    "SF_weather = pd.DataFrame()\n",
    "for station in SFshortlist['station_name']:\n",
    "    path = 'SF/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12784: \n",
    "            SF_stations.append(station)\n",
    "            if SF_weather.empty:\n",
    "                SF_weather = SF_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                SF_weather = SF_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "SF_weather = SF_weather.groupby('DATE').mean()\n",
    "SF_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######SD Weather######\n",
    "SD_stations = [];\n",
    "SD_weather = pd.DataFrame()\n",
    "for station in SDshortlist['station_name']:\n",
    "    path = 'SD/%s.csv' % station\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path,delim_whitespace=True)\n",
    "        frame = frame.query('TMIN != TMAX')\n",
    "        frame.columns = ['DATE', 'TMAX_'+station,'TMIN_'+station,'SNOW_'+station,'SNWD_'+station,'PRCP_'+station]\n",
    "        if frame.shape[0] >= 12600: \n",
    "            SD_stations.append(station)\n",
    "            if SD_weather.empty:\n",
    "                SD_weather = SD_weather.append(frame,ignore_index=True)\n",
    "            else:\n",
    "                SD_weather = SD_weather.merge(frame, on='DATE', how='inner', suffixes=('',''))\n",
    "SD_weather = SD_weather.groupby('DATE').mean()\n",
    "SD_weather.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Logger\n",
    "##### True indicates a missing data row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City stations missing data\n",
      "Station USC00300889\n",
      "False    12631\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00305426\n",
      "False    12631\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00094745\n",
      "False    12631\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00283951\n",
      "False    12631\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00014734\n",
      "False    12631\n",
      "dtype: int64\n",
      "()\n",
      "Atlanta stations missing data\n",
      "Station USC00092283\n",
      "False    12593\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00092485\n",
      "False    12593\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00093060\n",
      "False    12593\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00093621\n",
      "False    12593\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00093842\n",
      "False    12593\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00018469\n",
      "False    12593\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00013871\n",
      "False    12593\n",
      "dtype: int64\n",
      "()\n",
      "San Francisco stations missing data\n",
      "Station USC00043578\n",
      "False    12773\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00045795\n",
      "False    12773\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00047916\n",
      "False    12773\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00049742\n",
      "False    12773\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00023271\n",
      "False    12773\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00023272\n",
      "False    12773\n",
      "dtype: int64\n",
      "()\n",
      "San Diego stations missing data\n",
      "Station USC00040983\n",
      "False    12109\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00042239\n",
      "False    12109\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00043914\n",
      "False    12109\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00044223\n",
      "False    12109\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00003164\n",
      "False    12109\n",
      "dtype: int64\n",
      "()\n",
      "Los Angeles stations missing data\n",
      "Station USC00041194\n",
      "False    12106\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00046624\n",
      "False    12106\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00046719\n",
      "False    12106\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00047888\n",
      "False    12106\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00049152\n",
      "False    12106\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00049785\n",
      "False    12106\n",
      "dtype: int64\n",
      "()\n",
      "Chicago stations missing data\n",
      "Station USC00472869\n",
      "False    12652\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00473058\n",
      "False    12652\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00473453\n",
      "False    12652\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00476200\n",
      "False    12652\n",
      "dtype: int64\n",
      "()\n",
      "Station USW00014839\n",
      "False    12652\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00125174\n",
      "False    12652\n",
      "dtype: int64\n",
      "()\n",
      "Station USC00113262\n",
      "False    12652\n",
      "dtype: int64\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"New York City stations missing data\")\n",
    "for station in NYC_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(NYC_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Atlanta stations missing data\")\n",
    "for station in ATL_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(ATL_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "    \n",
    "print(\"San Francisco stations missing data\")\n",
    "for station in SF_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(SF_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"San Diego stations missing data\")\n",
    "for station in SD_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(SD_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Los Angeles stations missing data\")\n",
    "for station in LA_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(LA_weather)['TMIN_'+station].value_counts())\n",
    "    print()\n",
    "\n",
    "print(\"Chicago stations missing data\")\n",
    "for station in CH_stations:\n",
    "    print(\"Station %s\" % station)\n",
    "    print(pd.isnull(CH_weather)['TMIN_'+station].value_counts())\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Merge Datasets from each stock with PARAM_STOCK-NAME as default columns           \n",
    "######Stock Data######\n",
    "stocks = ['Apple, Inc Stock','International Business Machines Stock','Wal-Mart Stores, Inc Common St Stock','FedEx Corporation','The Boeing Company']\n",
    "stock_data = pd.DataFrame()\n",
    "for stock in stocks:\n",
    "    path = 'Stock Data/%s.csv' % stock\n",
    "    if os.path.exists(path):\n",
    "        frame = pd.read_csv(path)\n",
    "        frame.columns = ['DATE','OPEN_'+stock,'HIGH_'+stock,'LOW_'+stock,'CLOSE_'+stock,'VOLUME_'+stock,'ADJ CLOSE_'+stock]\n",
    "        if stock_data.empty:\n",
    "            stock_data = stock_data.append(frame,ignore_index=True)\n",
    "        else:\n",
    "            stock_data = stock_data.merge(frame, on='DATE', how='inner')\n",
    "stock_data = stock_data.groupby('DATE').mean()\n",
    "stock_data.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frames = [ATL_weather,CH_weather,NYC_weather,LA_weather,SD_weather,SF_weather,stock_data]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,how='inner',on='DATE'), data_frames)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  TMAX_USC00040983  TMAX_USC00042239  TMAX_USC00043914  \\\n",
      "TMAX_USC00040983          1.000000          0.909123          0.890611   \n",
      "TMAX_USC00042239          0.909123          1.000000          0.937859   \n",
      "TMAX_USC00043914          0.890611          0.937859          1.000000   \n",
      "TMAX_USC00044223          0.963431          0.899407          0.881659   \n",
      "TMAX_USW00003164          0.900046          0.885791          0.880609   \n",
      "\n",
      "                  TMAX_USC00044223  TMAX_USW00003164  \n",
      "TMAX_USC00040983          0.963431          0.900046  \n",
      "TMAX_USC00042239          0.899407          0.885791  \n",
      "TMAX_USC00043914          0.881659          0.880609  \n",
      "TMAX_USC00044223          1.000000          0.906180  \n",
      "TMAX_USW00003164          0.906180          1.000000  \n"
     ]
    }
   ],
   "source": [
    "SD_TMAX = pd.DataFrame()\n",
    "for column in list(SD_weather.columns.values):\n",
    "    if (re.match('TMAX',column)):\n",
    "        SD_TMAX[column] = SD_weather[column]\n",
    "print(SD_TMAX.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  TMIN_USC00043578  TMIN_USC00045795  TMIN_USC00047916  \\\n",
      "TMIN_USC00043578          1.000000          0.773245          0.875948   \n",
      "TMIN_USC00045795          0.773245          1.000000          0.863843   \n",
      "TMIN_USC00047916          0.875948          0.863843          1.000000   \n",
      "TMIN_USC00049742          0.809673          0.725458          0.824087   \n",
      "TMIN_USW00023271          0.822961          0.772047          0.849067   \n",
      "TMIN_USW00023272          0.774539          0.855064          0.808545   \n",
      "\n",
      "                  TMIN_USC00049742  TMIN_USW00023271  TMIN_USW00023272  \n",
      "TMIN_USC00043578          0.809673          0.822961          0.774539  \n",
      "TMIN_USC00045795          0.725458          0.772047          0.855064  \n",
      "TMIN_USC00047916          0.824087          0.849067          0.808545  \n",
      "TMIN_USC00049742          1.000000          0.933714          0.772974  \n",
      "TMIN_USW00023271          0.933714          1.000000          0.808318  \n",
      "TMIN_USW00023272          0.772974          0.808318          1.000000  \n"
     ]
    }
   ],
   "source": [
    "SF_TMIN = pd.DataFrame()\n",
    "for column in list(SF_weather.columns.values):\n",
    "    if (re.match('TMIN',column)):\n",
    "        SF_TMIN[column] = SF_weather[column]\n",
    "print(SF_TMIN.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  SNOW_USC00043578  SNOW_USC00045795  SNOW_USC00047916  \\\n",
      "SNOW_USC00043578               NaN               NaN               NaN   \n",
      "SNOW_USC00045795               NaN          1.000000               NaN   \n",
      "SNOW_USC00047916               NaN               NaN               NaN   \n",
      "SNOW_USC00049742               NaN          0.059015               NaN   \n",
      "SNOW_USW00023271               NaN         -0.000194               NaN   \n",
      "SNOW_USW00023272               NaN               NaN               NaN   \n",
      "\n",
      "                  SNOW_USC00049742  SNOW_USW00023271  SNOW_USW00023272  \n",
      "SNOW_USC00043578               NaN               NaN               NaN  \n",
      "SNOW_USC00045795          0.059015         -0.000194               NaN  \n",
      "SNOW_USC00047916               NaN               NaN               NaN  \n",
      "SNOW_USC00049742          1.000000         -0.000129               NaN  \n",
      "SNOW_USW00023271         -0.000129          1.000000               NaN  \n",
      "SNOW_USW00023272               NaN               NaN               NaN  \n"
     ]
    }
   ],
   "source": [
    "SF_SNOW = pd.DataFrame()\n",
    "for column in list(SF_weather.columns.values):\n",
    "    if (re.match('SNOW',column)):\n",
    "        SF_SNOW[column] = SF_weather[column]\n",
    "print(SF_SNOW.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  SNWD_USC00043578  SNWD_USC00045795  SNWD_USC00047916  \\\n",
      "SNWD_USC00043578                 1               NaN               NaN   \n",
      "SNWD_USC00045795               NaN               NaN               NaN   \n",
      "SNWD_USC00047916               NaN               NaN               NaN   \n",
      "SNWD_USC00049742               NaN               NaN               NaN   \n",
      "SNWD_USW00023271               NaN               NaN               NaN   \n",
      "SNWD_USW00023272               NaN               NaN               NaN   \n",
      "\n",
      "                  SNWD_USC00049742  SNWD_USW00023271  SNWD_USW00023272  \n",
      "SNWD_USC00043578               NaN               NaN               NaN  \n",
      "SNWD_USC00045795               NaN               NaN               NaN  \n",
      "SNWD_USC00047916               NaN               NaN               NaN  \n",
      "SNWD_USC00049742               NaN               NaN               NaN  \n",
      "SNWD_USW00023271               NaN               NaN               NaN  \n",
      "SNWD_USW00023272               NaN               NaN               NaN  \n"
     ]
    }
   ],
   "source": [
    "SF_SNWD = pd.DataFrame()\n",
    "for column in list(SF_weather.columns.values):\n",
    "    if (re.match('SNWD',column)):\n",
    "        SF_SNWD[column] = SF_weather[column]\n",
    "print(SF_SNWD.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  PRCP_USC00043578  PRCP_USC00045795  PRCP_USC00047916  \\\n",
      "PRCP_USC00043578          1.000000          0.618600          0.720685   \n",
      "PRCP_USC00045795          0.618600          1.000000          0.750712   \n",
      "PRCP_USC00047916          0.720685          0.750712          1.000000   \n",
      "PRCP_USC00049742          0.812961          0.645877          0.719130   \n",
      "PRCP_USW00023271          0.633869          0.616065          0.607253   \n",
      "PRCP_USW00023272          0.623863          0.612386          0.646948   \n",
      "\n",
      "                  PRCP_USC00049742  PRCP_USW00023271  PRCP_USW00023272  \n",
      "PRCP_USC00043578          0.812961          0.633869          0.623863  \n",
      "PRCP_USC00045795          0.645877          0.616065          0.612386  \n",
      "PRCP_USC00047916          0.719130          0.607253          0.646948  \n",
      "PRCP_USC00049742          1.000000          0.595812          0.546373  \n",
      "PRCP_USW00023271          0.595812          1.000000          0.786289  \n",
      "PRCP_USW00023272          0.546373          0.786289          1.000000  \n"
     ]
    }
   ],
   "source": [
    "SF_PRCP = pd.DataFrame()\n",
    "for column in list(SF_weather.columns.values):\n",
    "    if (re.match('PRCP',column)):\n",
    "        SF_PRCP[column] = SF_weather[column]\n",
    "print(SF_PRCP.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/athena/Documents/Weather Data\n"
     ]
    }
   ],
   "source": [
    "cd Documents/Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       207.500000\n",
      "1       272.000000\n",
      "2       294.500000\n",
      "3       263.833333\n",
      "4       213.000000\n",
      "           ...    \n",
      "7440    267.333333\n",
      "7441    239.833333\n",
      "7442    161.166667\n",
      "7443    172.333333\n",
      "7444    148.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "TMAX_AVG = [0 for x in xrange(len(df_final.index))]\n",
    "zipped = zip(list(df_final.columns.values),TMAX_AVG)\n",
    "count=0\n",
    "for i in list(df_final.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_AVG=TMAX_AVG+df_final.ix[:,i]\n",
    "\n",
    "\n",
    "################################################333\n",
    "TMAX_ATL = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_ATL=TMAX_ATL+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_ATL= TMAX_ATL/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMAX_CH = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_CH=TMAX_CH+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_CH= TMAX_CH/count \n",
    "###################################################3\n",
    "################################################333\n",
    "\n",
    "TMAX_LA = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_LA=TMAX_LA+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_LA= TMAX_LA/count\n",
    "print TMAX_AVG_LA\n",
    "\n",
    "###################################################3\n",
    "################################################333\n",
    "TMAX_NYC = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_NYC=TMAX_NYC+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_NYC= TMAX_NYC/count \n",
    "###################################################3\n",
    "################################################333\n",
    "\n",
    "TMAX_SD = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_SD=TMAX_SD+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_SD= TMAX_SD/count\n",
    "###################################################3\n",
    "################################################333\n",
    "TMAX_SF = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('TMAX',i)):\n",
    "        count=count+1\n",
    "        TMAX_SF=TMAX_SF+df_final.ix[:,i]\n",
    "\n",
    "TMAX_AVG_SF= TMAX_SF/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_ATL = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_ATL=TMIN_ATL+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_ATL= TMIN_ATL/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_CH = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_CH=TMIN_CH+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_CH= TMIN_CH/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_LA = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_LA=TMIN_LA+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_LA= TMIN_LA/count\n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_NYC = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_NYC=TMIN_NYC+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_NYC= TMIN_NYC/count \n",
    "###################################################3\n",
    "################################################333\n",
    "\n",
    "TMIN_SD = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_SD=TMIN_SD+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_SD= TMIN_SD/count \n",
    "###################################################3\n",
    "################################################333\n",
    "TMIN_SF = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('TMIN',i)):\n",
    "        count=count+1\n",
    "        TMIN_SF=TMIN_SF+df_final.ix[:,i]\n",
    "\n",
    "TMIN_AVG_SF= TMIN_SF/count \n",
    "###################################################3\n",
    "##################################################\n",
    "\n",
    "SNOW_ATL = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_ATL=SNOW_ATL+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_ATL= SNOW_ATL/count \n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNOW_NYC = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_NYC=SNOW_NYC+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_NYC= SNOW_NYC/count \n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_CH = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_CH=SNOW_CH+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_CH= SNOW_CH/count\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_LA = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_LA=SNOW_LA+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_LA= SNOW_LA/count\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_SD = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_SD=SNOW_SD+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_SD= SNOW_SD/count\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNOW_SF = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('SNOW',i)):\n",
    "        count=count+1\n",
    "        SNOW_SF=SNOW_SF+df_final.ix[:,i]\n",
    "\n",
    "SNOW_AVG_SF= SNOW_SF/count \n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "SNWD_ATL = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_ATL=SNWD_ATL+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_ATL= SNWD_ATL/count \n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_NYC = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_NYC=SNWD_NYC+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_NYC= SNWD_NYC/count\n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_CH = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_CH=SNWD_CH+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_CH= SNWD_CH/count \n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_LA = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_LA=SNWD_LA+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_LA= SNWD_LA/count \n",
    "\n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "SNWD_SD = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_SD=SNWD_SD+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_SD= SNWD_SD/count \n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "SNWD_SF = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('SNWD',i)):\n",
    "        count=count+1\n",
    "        SNWD_SF=SNWD_SF+df_final.ix[:,i]\n",
    "\n",
    "SNWD_AVG_SF= SNWD_SF/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "PRCP_NYC = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(NYC_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_NYC=PRCP_NYC+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_NYC= PRCP_NYC/count\n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_ATL = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(ATL_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_ATL=PRCP_ATL+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_ATL= PRCP_ATL/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_CH = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(CH_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_CH=PRCP_CH+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_CH= PRCP_CH/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_LA = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(LA_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_LA=PRCP_LA+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_LA= PRCP_LA/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_SD = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SD_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_SD=PRCP_SD+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_SD= PRCP_SD/count \n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "PRCP_SF = [0 for x in xrange(len(df_final.index))]\n",
    "count=0\n",
    "for i in list(SF_weather.columns.values):\n",
    "    if(re.match('PRCP',i)):\n",
    "        count=count+1\n",
    "        PRCP_SF=PRCP_SF+df_final.ix[:,i]\n",
    "\n",
    "PRCP_AVG_SF= PRCP_SF/count \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"TMAX_ATL\"]=TMAX_AVG_ATL\n",
    "df[\"TMAX_NYC\"]=TMAX_AVG_NYC\n",
    "df[\"TMAX_CH\"]=TMAX_AVG_CH\n",
    "df[\"TMAX_LA\"]=TMAX_AVG_LA\n",
    "df[\"TMAX_SD\"]=TMAX_AVG_SD\n",
    "df[\"TMAX_SF\"]=TMAX_AVG_SF\n",
    "\n",
    "\n",
    "df[\"TMIN_ATL\"]=TMIN_AVG_ATL\n",
    "df[\"TMIN_NYC\"]=TMIN_AVG_NYC\n",
    "df[\"TMIN_CH\"]=TMIN_AVG_CH\n",
    "df[\"TMIN_LA\"]=TMIN_AVG_LA\n",
    "df[\"TMIN_SD\"]=TMIN_AVG_SD\n",
    "df[\"TMIN_SF\"]=TMIN_AVG_SF \n",
    "\n",
    "df[\"SNOW_ATL\"]=SNOW_AVG_ATL\n",
    "df[\"SNOW_NYC\"]=SNOW_AVG_NYC\n",
    "df[\"SNOW_CH\"]=SNOW_AVG_CH\n",
    "df[\"SNOW_LA\"]=SNOW_AVG_LA\n",
    "df[\"SNOW_SD\"]=SNOW_AVG_SD\n",
    "df[\"SNOW_SF\"]=SNOW_AVG_SF \n",
    "\n",
    "df[\"SNWD_ATL\"]=SNWD_AVG_ATL\n",
    "df[\"SNWD_NYC\"]=SNWD_AVG_NYC\n",
    "df[\"SNWD_CH\"]=SNWD_AVG_CH\n",
    "df[\"SNWD_LA\"]=SNWD_AVG_LA\n",
    "df[\"SNWD_SD\"]=SNWD_AVG_SD\n",
    "df[\"SNWD_SF\"]=SNWD_AVG_SF \n",
    "\n",
    "df[\"PRCP_ATL\"]=PRCP_AVG_ATL\n",
    "df[\"PRCP_NYC\"]=PRCP_AVG_NYC\n",
    "df[\"PRCP_CH\"]=PRCP_AVG_CH\n",
    "df[\"PRCP_LA\"]=PRCP_AVG_LA\n",
    "df[\"PRCP_SD\"]=PRCP_AVG_SD\n",
    "df[\"PRCP_SF\"]=PRCP_AVG_SF \n",
    "\n",
    "df[\"WalMart\"]= -np.log(df_final[\"OPEN_Wal-Mart Stores, Inc Common St Stock\"])+ np.log(df_final[\"CLOSE_Wal-Mart Stores, Inc Common St Stock\"])  \n",
    "\n",
    "df[\"Apple\"]= -np.log(df_final[\"OPEN_Apple, Inc Stock\"])+ np.log(df_final[\"CLOSE_Apple, Inc Stock\"])\n",
    "                                                               \n",
    "df[\"Boeing\"]= -np.log(df_final[\"OPEN_The Boeing Company\"])+ np.log(df_final[\"CLOSE_The Boeing Company\"]) \n",
    "\n",
    "df[\"FedEx\"]= -np.log(df_final[\"OPEN_FedEx Corporation\"])+ np.log(df_final[\"CLOSE_FedEx Corporation\"])  \n",
    "\n",
    "df[\"IBM\"]= -np.log(df_final[\"OPEN_International Business Machines Stock\"])+ np.log(df_final[\"CLOSE_International Business Machines Stock\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMAX_ATL</th>\n",
       "      <th>TMAX_NYC</th>\n",
       "      <th>TMAX_CH</th>\n",
       "      <th>TMAX_LA</th>\n",
       "      <th>TMAX_SD</th>\n",
       "      <th>TMAX_SF</th>\n",
       "      <th>TMIN_ATL</th>\n",
       "      <th>TMIN_NYC</th>\n",
       "      <th>TMIN_CH</th>\n",
       "      <th>TMIN_LA</th>\n",
       "      <th>...</th>\n",
       "      <th>PRCP_NYC</th>\n",
       "      <th>PRCP_CH</th>\n",
       "      <th>PRCP_LA</th>\n",
       "      <th>PRCP_SD</th>\n",
       "      <th>PRCP_SF</th>\n",
       "      <th>WalMart</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Boeing</th>\n",
       "      <th>FedEx</th>\n",
       "      <th>IBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "      <td>7445.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>222.681147</td>\n",
       "      <td>162.972612</td>\n",
       "      <td>138.940209</td>\n",
       "      <td>252.412536</td>\n",
       "      <td>261.811699</td>\n",
       "      <td>215.009413</td>\n",
       "      <td>97.290540</td>\n",
       "      <td>64.938428</td>\n",
       "      <td>30.257354</td>\n",
       "      <td>113.846172</td>\n",
       "      <td>...</td>\n",
       "      <td>33.838522</td>\n",
       "      <td>24.910755</td>\n",
       "      <td>10.754914</td>\n",
       "      <td>11.545467</td>\n",
       "      <td>17.482024</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82.122829</td>\n",
       "      <td>100.163362</td>\n",
       "      <td>118.439630</td>\n",
       "      <td>60.193860</td>\n",
       "      <td>81.548675</td>\n",
       "      <td>55.969511</td>\n",
       "      <td>84.820201</td>\n",
       "      <td>92.613697</td>\n",
       "      <td>107.281860</td>\n",
       "      <td>46.107138</td>\n",
       "      <td>...</td>\n",
       "      <td>71.406898</td>\n",
       "      <td>52.550098</td>\n",
       "      <td>52.700786</td>\n",
       "      <td>48.710351</td>\n",
       "      <td>55.976887</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.014392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-132.200000</td>\n",
       "      <td>-235.000000</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>53.833333</td>\n",
       "      <td>-183.857143</td>\n",
       "      <td>-223.200000</td>\n",
       "      <td>-325.285714</td>\n",
       "      <td>-34.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.125418</td>\n",
       "      <td>-0.279082</td>\n",
       "      <td>-0.108698</td>\n",
       "      <td>-0.151685</td>\n",
       "      <td>-0.268122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>161.142857</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>40.285714</td>\n",
       "      <td>206.500000</td>\n",
       "      <td>196.400000</td>\n",
       "      <td>168.500000</td>\n",
       "      <td>28.428571</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-41.285714</td>\n",
       "      <td>77.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007580</td>\n",
       "      <td>-0.013011</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>-0.009238</td>\n",
       "      <td>-0.007255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>233.285714</td>\n",
       "      <td>167.800000</td>\n",
       "      <td>149.285714</td>\n",
       "      <td>252.833333</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>218.500000</td>\n",
       "      <td>101.571429</td>\n",
       "      <td>64.400000</td>\n",
       "      <td>33.285714</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>292.714286</td>\n",
       "      <td>252.200000</td>\n",
       "      <td>245.142857</td>\n",
       "      <td>299.166667</td>\n",
       "      <td>337.600000</td>\n",
       "      <td>258.333333</td>\n",
       "      <td>177.857143</td>\n",
       "      <td>145.600000</td>\n",
       "      <td>120.714286</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.007565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>387.285714</td>\n",
       "      <td>382.200000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>426.833333</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>391.666667</td>\n",
       "      <td>238.142857</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>261.285714</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>797.400000</td>\n",
       "      <td>727.285714</td>\n",
       "      <td>977.333333</td>\n",
       "      <td>875.200000</td>\n",
       "      <td>702.833333</td>\n",
       "      <td>0.190807</td>\n",
       "      <td>0.176186</td>\n",
       "      <td>0.108548</td>\n",
       "      <td>0.133904</td>\n",
       "      <td>0.122086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TMAX_ATL     TMAX_NYC      TMAX_CH      TMAX_LA      TMAX_SD  \\\n",
       "count  7445.000000  7445.000000  7445.000000  7445.000000  7445.000000   \n",
       "mean    222.681147   162.972612   138.940209   252.412536   261.811699   \n",
       "std      82.122829   100.163362   118.439630    60.193860    81.548675   \n",
       "min     -53.000000  -132.200000  -235.000000    70.333333    48.800000   \n",
       "25%     161.142857    81.000000    40.285714   206.500000   196.400000   \n",
       "50%     233.285714   167.800000   149.285714   252.833333   259.000000   \n",
       "75%     292.714286   252.200000   245.142857   299.166667   337.600000   \n",
       "max     387.285714   382.200000   384.000000   426.833333   442.000000   \n",
       "\n",
       "           TMAX_SF     TMIN_ATL     TMIN_NYC      TMIN_CH      TMIN_LA  \\\n",
       "count  7445.000000  7445.000000  7445.000000  7445.000000  7445.000000   \n",
       "mean    215.009413    97.290540    64.938428    30.257354   113.846172   \n",
       "std      55.969511    84.820201    92.613697   107.281860    46.107138   \n",
       "min      53.833333  -183.857143  -223.200000  -325.285714   -34.166667   \n",
       "25%     168.500000    28.428571    -4.600000   -41.285714    77.833333   \n",
       "50%     218.500000   101.571429    64.400000    33.285714   113.000000   \n",
       "75%     258.333333   177.857143   145.600000   120.714286   151.000000   \n",
       "max     391.666667   238.142857   259.000000   261.285714   237.000000   \n",
       "\n",
       "          ...          PRCP_NYC      PRCP_CH      PRCP_LA      PRCP_SD  \\\n",
       "count     ...       7445.000000  7445.000000  7445.000000  7445.000000   \n",
       "mean      ...         33.838522    24.910755    10.754914    11.545467   \n",
       "std       ...         71.406898    52.550098    52.700786    48.710351   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          1.600000     2.571429     0.000000     0.000000   \n",
       "75%       ...         32.200000    25.000000     0.000000     0.000000   \n",
       "max       ...        797.400000   727.285714   977.333333   875.200000   \n",
       "\n",
       "           PRCP_SF      WalMart        Apple       Boeing        FedEx  \\\n",
       "count  7445.000000  7445.000000  7445.000000  7445.000000  7445.000000   \n",
       "mean     17.482024     0.000410    -0.000542     0.000229     0.000527   \n",
       "std      55.976887     0.015883     0.024965     0.016251     0.017820   \n",
       "min       0.000000    -0.125418    -0.279082    -0.108698    -0.151685   \n",
       "25%       0.000000    -0.007580    -0.013011    -0.008791    -0.009238   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.666667     0.008156     0.011664     0.008985     0.009675   \n",
       "max     702.833333     0.190807     0.176186     0.108548     0.133904   \n",
       "\n",
       "               IBM  \n",
       "count  7445.000000  \n",
       "mean      0.000159  \n",
       "std       0.014392  \n",
       "min      -0.268122  \n",
       "25%      -0.007255  \n",
       "50%       0.000000  \n",
       "75%       0.007565  \n",
       "max       0.122086  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "res = defaultdict(dict)\n",
    "\n",
    "X = pd.DataFrame(df.ix[:,0:30])\n",
    "Y = pd.DataFrame(df.ix[:,31:35])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y.ix[:,0], test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.1, 0.01],\n",
    "              'max_depth': [1,2],\n",
    "              'min_samples_leaf': [8],\n",
    "              'max_features': [1.0]\n",
    "              }\n",
    "\n",
    "est = GradientBoostingRegressor(n_estimators=300)\n",
    "# this may take some minutes\n",
    "gs_cv = GridSearchCV(est, param_grid, scoring='mean_squared_error', n_jobs=4).fit(X_train, y_train)\n",
    "\n",
    "# best hyperparameter setting\n",
    "print('Best hyperparameters: %r' % gs_cv.best_params_)\n",
    "#print \"abc\"\n",
    "#regressor = DecisionTreeRegressor(max_depth = 1,random_state=0)\n",
    "#print cross_val_score(regressor, X, Y.ix[:,0], cv=10)\n",
    "\n",
    "# predict class labels\n",
    "#pred = est.predict(X_test)\n",
    "\n",
    "# score on test data (accuracy)\n",
    "#testacc = est.score(X_test, y_test)\n",
    "#trainacc = est.score(X_train,y_train)\n",
    "\n",
    "#print('TestACC: %.4f' % testacc)\n",
    "#print('TrainACC:%.4f' % trainacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs\n"
     ]
    }
   ],
   "source": [
    "print \"abs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/athena/stock-proj/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/athena/Documents/Weather Data\n"
     ]
    }
   ],
   "source": [
    "cd Documents/Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"stockweather.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/athena\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
